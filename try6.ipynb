{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "static_data = pd.read_csv(r\"datasets\\static_client_data.csv\")\n",
    "historical_data = pd.read_csv(r\"datasets\\time_series_data.csv\")\n",
    "target_data = pd.read_csv(r\"datasets\\target_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns_to_merge = [\n",
    "    'client_id', 'age', 'employment_status', 'annual_income',\n",
    "    'debt_to_income_ratio', 'financial_knowledge_score',\n",
    "    'risk_appetite', 'investment_horizon_years',\n",
    "    'savings_rate', 'net_worth'\n",
    "]\n",
    "\n",
    "df_merged = historical_data.merge(static_data[columns_to_merge], on='client_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              client_id       month  portfolio_value  \\\n",
      "0  96c4c0a3-bb3f-4ac1-81ad-0850cd29911f  01-03-2022         89775.68   \n",
      "1  96c4c0a3-bb3f-4ac1-81ad-0850cd29911f  01-04-2022         89685.96   \n",
      "2  96c4c0a3-bb3f-4ac1-81ad-0850cd29911f  01-05-2022         90114.05   \n",
      "3  96c4c0a3-bb3f-4ac1-81ad-0850cd29911f  01-06-2022         90338.07   \n",
      "4  96c4c0a3-bb3f-4ac1-81ad-0850cd29911f  01-07-2022         92449.25   \n",
      "\n",
      "   equity_allocation_pct  fixed_income_allocation_pct  monthly_contribution  \\\n",
      "0                  56.07                        43.93               1562.11   \n",
      "1                  32.74                        67.26                772.74   \n",
      "2                  56.71                        43.29                709.24   \n",
      "3                  67.11                        32.89                799.51   \n",
      "4                  23.90                        76.10               1923.33   \n",
      "\n",
      "   market_volatility_index  macroeconomic_score  sentiment_index  age  \\\n",
      "0                    10.41                 7.85             7.16   63   \n",
      "1                    13.67                 4.52             5.62   63   \n",
      "2                    15.84                 4.83             5.28   63   \n",
      "3                    20.28                 5.96             3.23   63   \n",
      "4                    29.31                 7.04             4.52   63   \n",
      "\n",
      "  employment_status  annual_income  debt_to_income_ratio  \\\n",
      "0          Salaried       61244.14                  0.49   \n",
      "1          Salaried       61244.14                  0.49   \n",
      "2          Salaried       61244.14                  0.49   \n",
      "3          Salaried       61244.14                  0.49   \n",
      "4          Salaried       61244.14                  0.49   \n",
      "\n",
      "   financial_knowledge_score risk_appetite  investment_horizon_years  \\\n",
      "0                          5        Medium                         9   \n",
      "1                          5        Medium                         9   \n",
      "2                          5        Medium                         9   \n",
      "3                          5        Medium                         9   \n",
      "4                          5        Medium                         9   \n",
      "\n",
      "   savings_rate  net_worth recommended_strategy  \n",
      "0          0.09  150946.53         Conservative  \n",
      "1          0.09  150946.53         Conservative  \n",
      "2          0.09  150946.53         Conservative  \n",
      "3          0.09  150946.53         Conservative  \n",
      "4          0.09  150946.53         Conservative  \n"
     ]
    }
   ],
   "source": [
    "# Merge with target data (only taking 'recommended_strategy')\n",
    "df_merged = df_merged.merge(target_data[[\"client_id\", \"recommended_strategy\"]], on=\"client_id\", how=\"left\")\n",
    "\n",
    "# Check the final dataset\n",
    "print(df_merged.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File saved successfully at: datasets/classification_data.csv\n"
     ]
    }
   ],
   "source": [
    "# Define the path where you want to save the file\n",
    "save_path = \"datasets/classification_data.csv\"\n",
    "\n",
    "# Save the merged data as a CSV file\n",
    "df_merged.to_csv(save_path, index=False)\n",
    "\n",
    "print(f\"File saved successfully at: {save_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>client_id</th>\n",
       "      <th>month</th>\n",
       "      <th>portfolio_value</th>\n",
       "      <th>equity_allocation_pct</th>\n",
       "      <th>fixed_income_allocation_pct</th>\n",
       "      <th>monthly_contribution</th>\n",
       "      <th>market_volatility_index</th>\n",
       "      <th>macroeconomic_score</th>\n",
       "      <th>sentiment_index</th>\n",
       "      <th>age</th>\n",
       "      <th>employment_status</th>\n",
       "      <th>annual_income</th>\n",
       "      <th>debt_to_income_ratio</th>\n",
       "      <th>financial_knowledge_score</th>\n",
       "      <th>risk_appetite</th>\n",
       "      <th>investment_horizon_years</th>\n",
       "      <th>savings_rate</th>\n",
       "      <th>net_worth</th>\n",
       "      <th>recommended_strategy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>96c4c0a3-bb3f-4ac1-81ad-0850cd29911f</td>\n",
       "      <td>01-03-2022</td>\n",
       "      <td>89775.68</td>\n",
       "      <td>56.07</td>\n",
       "      <td>43.93</td>\n",
       "      <td>1562.11</td>\n",
       "      <td>10.41</td>\n",
       "      <td>7.85</td>\n",
       "      <td>7.16</td>\n",
       "      <td>63</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>61244.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>9</td>\n",
       "      <td>0.09</td>\n",
       "      <td>150946.53</td>\n",
       "      <td>Conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>96c4c0a3-bb3f-4ac1-81ad-0850cd29911f</td>\n",
       "      <td>01-04-2022</td>\n",
       "      <td>89685.96</td>\n",
       "      <td>32.74</td>\n",
       "      <td>67.26</td>\n",
       "      <td>772.74</td>\n",
       "      <td>13.67</td>\n",
       "      <td>4.52</td>\n",
       "      <td>5.62</td>\n",
       "      <td>63</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>61244.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>9</td>\n",
       "      <td>0.09</td>\n",
       "      <td>150946.53</td>\n",
       "      <td>Conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>96c4c0a3-bb3f-4ac1-81ad-0850cd29911f</td>\n",
       "      <td>01-05-2022</td>\n",
       "      <td>90114.05</td>\n",
       "      <td>56.71</td>\n",
       "      <td>43.29</td>\n",
       "      <td>709.24</td>\n",
       "      <td>15.84</td>\n",
       "      <td>4.83</td>\n",
       "      <td>5.28</td>\n",
       "      <td>63</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>61244.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>9</td>\n",
       "      <td>0.09</td>\n",
       "      <td>150946.53</td>\n",
       "      <td>Conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>96c4c0a3-bb3f-4ac1-81ad-0850cd29911f</td>\n",
       "      <td>01-06-2022</td>\n",
       "      <td>90338.07</td>\n",
       "      <td>67.11</td>\n",
       "      <td>32.89</td>\n",
       "      <td>799.51</td>\n",
       "      <td>20.28</td>\n",
       "      <td>5.96</td>\n",
       "      <td>3.23</td>\n",
       "      <td>63</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>61244.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>9</td>\n",
       "      <td>0.09</td>\n",
       "      <td>150946.53</td>\n",
       "      <td>Conservative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>96c4c0a3-bb3f-4ac1-81ad-0850cd29911f</td>\n",
       "      <td>01-07-2022</td>\n",
       "      <td>92449.25</td>\n",
       "      <td>23.90</td>\n",
       "      <td>76.10</td>\n",
       "      <td>1923.33</td>\n",
       "      <td>29.31</td>\n",
       "      <td>7.04</td>\n",
       "      <td>4.52</td>\n",
       "      <td>63</td>\n",
       "      <td>Salaried</td>\n",
       "      <td>61244.14</td>\n",
       "      <td>0.49</td>\n",
       "      <td>5</td>\n",
       "      <td>Medium</td>\n",
       "      <td>9</td>\n",
       "      <td>0.09</td>\n",
       "      <td>150946.53</td>\n",
       "      <td>Conservative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              client_id       month  portfolio_value  \\\n",
       "0  96c4c0a3-bb3f-4ac1-81ad-0850cd29911f  01-03-2022         89775.68   \n",
       "1  96c4c0a3-bb3f-4ac1-81ad-0850cd29911f  01-04-2022         89685.96   \n",
       "2  96c4c0a3-bb3f-4ac1-81ad-0850cd29911f  01-05-2022         90114.05   \n",
       "3  96c4c0a3-bb3f-4ac1-81ad-0850cd29911f  01-06-2022         90338.07   \n",
       "4  96c4c0a3-bb3f-4ac1-81ad-0850cd29911f  01-07-2022         92449.25   \n",
       "\n",
       "   equity_allocation_pct  fixed_income_allocation_pct  monthly_contribution  \\\n",
       "0                  56.07                        43.93               1562.11   \n",
       "1                  32.74                        67.26                772.74   \n",
       "2                  56.71                        43.29                709.24   \n",
       "3                  67.11                        32.89                799.51   \n",
       "4                  23.90                        76.10               1923.33   \n",
       "\n",
       "   market_volatility_index  macroeconomic_score  sentiment_index  age  \\\n",
       "0                    10.41                 7.85             7.16   63   \n",
       "1                    13.67                 4.52             5.62   63   \n",
       "2                    15.84                 4.83             5.28   63   \n",
       "3                    20.28                 5.96             3.23   63   \n",
       "4                    29.31                 7.04             4.52   63   \n",
       "\n",
       "  employment_status  annual_income  debt_to_income_ratio  \\\n",
       "0          Salaried       61244.14                  0.49   \n",
       "1          Salaried       61244.14                  0.49   \n",
       "2          Salaried       61244.14                  0.49   \n",
       "3          Salaried       61244.14                  0.49   \n",
       "4          Salaried       61244.14                  0.49   \n",
       "\n",
       "   financial_knowledge_score risk_appetite  investment_horizon_years  \\\n",
       "0                          5        Medium                         9   \n",
       "1                          5        Medium                         9   \n",
       "2                          5        Medium                         9   \n",
       "3                          5        Medium                         9   \n",
       "4                          5        Medium                         9   \n",
       "\n",
       "   savings_rate  net_worth recommended_strategy  \n",
       "0          0.09  150946.53         Conservative  \n",
       "1          0.09  150946.53         Conservative  \n",
       "2          0.09  150946.53         Conservative  \n",
       "3          0.09  150946.53         Conservative  \n",
       "4          0.09  150946.53         Conservative  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_merged.columns\n",
    "df_merged.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load data\n",
    "df = pd.read_csv(\"datasets/classification_data.csv\")\n",
    "\n",
    "# Encode target\n",
    "le = LabelEncoder()\n",
    "df['target'] = le.fit_transform(df['recommended_strategy'])\n",
    "\n",
    "# Drop static columns\n",
    "static_cols = ['recommended_strategy', 'employment_status', 'risk_appetite']\n",
    "df = df.drop(columns=static_cols)\n",
    "\n",
    "# Group by client\n",
    "grouped = df.groupby('client_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['client_id', 'month', 'portfolio_value', 'equity_allocation_pct', 'fixed_income_allocation_pct', 'monthly_contribution', 'market_volatility_index', 'macroeconomic_score', 'sentiment_index', 'age', 'annual_income', 'debt_to_income_ratio', 'financial_knowledge_score', 'investment_horizon_years', 'savings_rate', 'net_worth', 'target']\n"
     ]
    }
   ],
   "source": [
    "print(df.columns.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "df_cleaned = df.copy()\n",
    "categorical_cols = df_cleaned.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Drop 'client_id' and 'month' — not needed for modeling\n",
    "categorical_cols = [col for col in categorical_cols if col not in ['client_id', 'month', 'target']]\n",
    "\n",
    "# Apply LabelEncoder\n",
    "le_dict = {}\n",
    "for col in categorical_cols:\n",
    "    le = LabelEncoder()\n",
    "    df_cleaned[col] = le.fit_transform(df_cleaned[col])\n",
    "    le_dict[col] = le  # Optional: save encoders if needed later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "client_id                       object\n",
      "month                           object\n",
      "portfolio_value                float64\n",
      "equity_allocation_pct          float64\n",
      "fixed_income_allocation_pct    float64\n",
      "monthly_contribution           float64\n",
      "market_volatility_index        float64\n",
      "macroeconomic_score            float64\n",
      "sentiment_index                float64\n",
      "age                              int64\n",
      "annual_income                  float64\n",
      "debt_to_income_ratio           float64\n",
      "financial_knowledge_score        int64\n",
      "investment_horizon_years         int64\n",
      "savings_rate                   float64\n",
      "net_worth                      float64\n",
      "target                           int32\n",
      "dtype: object\n"
     ]
    }
   ],
   "source": [
    "print(df_cleaned.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">LSTM</span>)                     │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │        <span style=\"color: #00af00; text-decoration-color: #00af00\">20,224</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ lstm (\u001b[38;5;33mLSTM\u001b[0m)                     │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │        \u001b[38;5;34m20,224\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m2,080\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              │            \u001b[38;5;34m99\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,403</span> (87.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m22,403\u001b[0m (87.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">22,403</span> (87.51 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m22,403\u001b[0m (87.51 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 18ms/step - accuracy: 0.4697 - loss: 1.0567 - val_accuracy: 0.5175 - val_loss: 1.0158\n",
      "Epoch 2/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 15ms/step - accuracy: 0.4988 - loss: 1.0311 - val_accuracy: 0.5163 - val_loss: 1.0201\n",
      "Epoch 3/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 38ms/step - accuracy: 0.5057 - loss: 1.0223 - val_accuracy: 0.5175 - val_loss: 1.0213\n",
      "Epoch 4/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 37ms/step - accuracy: 0.5166 - loss: 1.0089 - val_accuracy: 0.5088 - val_loss: 1.0220\n",
      "Epoch 5/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.5104 - loss: 1.0146 - val_accuracy: 0.5025 - val_loss: 1.0292\n",
      "Epoch 6/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 37ms/step - accuracy: 0.5034 - loss: 1.0128 - val_accuracy: 0.5063 - val_loss: 1.0280\n",
      "Epoch 7/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 34ms/step - accuracy: 0.5055 - loss: 1.0134 - val_accuracy: 0.5000 - val_loss: 1.0308\n",
      "Epoch 8/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 22ms/step - accuracy: 0.4978 - loss: 1.0146 - val_accuracy: 0.4988 - val_loss: 1.0377\n",
      "Epoch 9/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 28ms/step - accuracy: 0.5189 - loss: 1.0020 - val_accuracy: 0.4900 - val_loss: 1.0384\n",
      "Epoch 10/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 32ms/step - accuracy: 0.5073 - loss: 0.9988 - val_accuracy: 0.4888 - val_loss: 1.0398\n",
      "Epoch 11/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 35ms/step - accuracy: 0.5263 - loss: 0.9864 - val_accuracy: 0.4850 - val_loss: 1.0535\n",
      "Epoch 12/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 33ms/step - accuracy: 0.5283 - loss: 0.9740 - val_accuracy: 0.4837 - val_loss: 1.0516\n",
      "Epoch 13/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 36ms/step - accuracy: 0.5428 - loss: 0.9699 - val_accuracy: 0.4737 - val_loss: 1.0592\n",
      "Epoch 14/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 32ms/step - accuracy: 0.5385 - loss: 0.9584 - val_accuracy: 0.4737 - val_loss: 1.0703\n",
      "Epoch 15/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 27ms/step - accuracy: 0.5474 - loss: 0.9502 - val_accuracy: 0.4675 - val_loss: 1.0900\n",
      "Epoch 16/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 38ms/step - accuracy: 0.5579 - loss: 0.9279 - val_accuracy: 0.4650 - val_loss: 1.0979\n",
      "Epoch 17/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 37ms/step - accuracy: 0.5537 - loss: 0.9247 - val_accuracy: 0.4175 - val_loss: 1.1205\n",
      "Epoch 18/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 30ms/step - accuracy: 0.5678 - loss: 0.9123 - val_accuracy: 0.4375 - val_loss: 1.1273\n",
      "Epoch 19/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 35ms/step - accuracy: 0.5838 - loss: 0.8936 - val_accuracy: 0.4363 - val_loss: 1.1464\n",
      "Epoch 20/20\n",
      "\u001b[1m450/450\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 38ms/step - accuracy: 0.5895 - loss: 0.8733 - val_accuracy: 0.4225 - val_loss: 1.1505\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 24ms/step - accuracy: 0.4218 - loss: 1.1584\n",
      "Test Accuracy: 0.4210\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Dropout\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "# Load your preprocessed dataset (or use df directly if it's already loaded)\n",
    "# df = pd.read_csv(\"your_file.csv\")  # Skip if already in memory\n",
    "\n",
    "# Drop 'client_id' and sort by time\n",
    "df = df.sort_values(by=['client_id', 'month'])\n",
    "\n",
    "# Group by client_id\n",
    "grouped = df.groupby('client_id')\n",
    "\n",
    "sequences = []\n",
    "labels = []\n",
    "\n",
    "for client_id, group in grouped:\n",
    "    X = group.drop(columns=['client_id', 'month', 'target']).values\n",
    "    y = group['target'].values[0]  # Assume same target for all months\n",
    "    sequences.append(X)\n",
    "    labels.append(y)\n",
    "\n",
    "# Convert to NumPy arrays\n",
    "X = np.array(sequences)\n",
    "y = np.array(labels)\n",
    "\n",
    "# Reshape and scale\n",
    "num_samples, timesteps, num_features = X.shape\n",
    "X_scaled = StandardScaler().fit_transform(X.reshape(-1, num_features)).reshape(num_samples, timesteps, num_features)\n",
    "\n",
    "# One-hot encode target\n",
    "y_encoded = to_categorical(y)\n",
    "\n",
    "# Train-test split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_encoded, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(64, input_shape=(timesteps, num_features), return_sequences=False))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(y_encoded.shape[1], activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "model.summary()\n",
    "\n",
    "# Train\n",
    "model.fit(X_train, y_train, epochs=20, batch_size=16, validation_split=0.1)\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 34ms/step - accuracy: 0.3319 - loss: 1.1001 - val_accuracy: 0.3025 - val_loss: 1.1025 - learning_rate: 5.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 35ms/step - accuracy: 0.3074 - loss: 1.1006 - val_accuracy: 0.3219 - val_loss: 1.0972 - learning_rate: 5.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.3632 - loss: 1.0975 - val_accuracy: 0.3406 - val_loss: 1.0976 - learning_rate: 5.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.3571 - loss: 1.0896 - val_accuracy: 0.3425 - val_loss: 1.0978 - learning_rate: 5.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m 99/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m━\u001b[0m \u001b[1m0s\u001b[0m 30ms/step - accuracy: 0.3965 - loss: 1.0826\n",
      "Epoch 5: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 35ms/step - accuracy: 0.3963 - loss: 1.0828 - val_accuracy: 0.2825 - val_loss: 1.1115 - learning_rate: 5.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.3786 - loss: 1.0796 - val_accuracy: 0.2956 - val_loss: 1.1083 - learning_rate: 2.5000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.3600 - loss: 1.0864 - val_accuracy: 0.3262 - val_loss: 1.1008 - learning_rate: 2.5000e-04\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.3462 - loss: 1.0955\n",
      "✅ Test Accuracy: 0.3480\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Input, LSTM, Dense, Dropout, Bidirectional, BatchNormalization\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "from keras.losses import CategoricalCrossentropy\n",
    "\n",
    "# Optional: Use focal loss if highly imbalanced\n",
    "# !pip install keras-losses  # only if needed\n",
    "# from keras_losses import CategoricalFocalCrossentropy\n",
    "# loss_fn = CategoricalFocalCrossentropy(gamma=2.0)\n",
    "\n",
    "model = Sequential([\n",
    "    Input(shape=(X.shape[1], X.shape[2])),\n",
    "    Bidirectional(LSTM(128, return_sequences=True)),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Bidirectional(LSTM(64)),\n",
    "    Dropout(0.3),\n",
    "    BatchNormalization(),\n",
    "    \n",
    "    Dense(64, activation='relu'),\n",
    "    Dropout(0.2),\n",
    "    \n",
    "    Dense(y_cat.shape[1], activation='softmax')\n",
    "])\n",
    "\n",
    "model.compile(\n",
    "    loss=CategoricalCrossentropy(),  # or loss_fn\n",
    "    optimizer=Adam(learning_rate=0.0003),\n",
    "    metrics=['accuracy', Precision(), Recall()]\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(patience=5, monitor='val_loss', restore_best_weights=True),\n",
    "    ReduceLROnPlateau(patience=3, factor=0.5, verbose=1)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    class_weight=cw_dict,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, acc, prec, rec = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"✅ Test Accuracy: {acc:.4f} | Precision: {prec:.4f} | Recall: {rec:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\rnn\\rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 105ms/step - accuracy: 0.4681 - loss: 1.0548 - val_accuracy: 0.4919 - val_loss: 1.0420 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.5016 - loss: 1.0282 - val_accuracy: 0.4919 - val_loss: 1.0383 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 93ms/step - accuracy: 0.4953 - loss: 1.0314 - val_accuracy: 0.4925 - val_loss: 1.0370 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 76ms/step - accuracy: 0.5055 - loss: 1.0231 - val_accuracy: 0.4925 - val_loss: 1.0378 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 104ms/step - accuracy: 0.5092 - loss: 1.0203 - val_accuracy: 0.4925 - val_loss: 1.0405 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 105ms/step - accuracy: 0.5145 - loss: 1.0150\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 118ms/step - accuracy: 0.5145 - loss: 1.0151 - val_accuracy: 0.4925 - val_loss: 1.0391 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 149ms/step - accuracy: 0.5016 - loss: 1.0165 - val_accuracy: 0.4925 - val_loss: 1.0419 - learning_rate: 5.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 115ms/step - accuracy: 0.4981 - loss: 1.0212 - val_accuracy: 0.4913 - val_loss: 1.0455 - learning_rate: 5.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.5133 - loss: 1.0104\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 94ms/step - accuracy: 0.5133 - loss: 1.0104 - val_accuracy: 0.4913 - val_loss: 1.0436 - learning_rate: 5.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 99ms/step - accuracy: 0.5063 - loss: 1.0050 - val_accuracy: 0.4888 - val_loss: 1.0501 - learning_rate: 2.5000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 100ms/step - accuracy: 0.5101 - loss: 1.0023 - val_accuracy: 0.4881 - val_loss: 1.0522 - learning_rate: 2.5000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 137ms/step - accuracy: 0.5095 - loss: 1.0021\n",
      "Epoch 12: ReduceLROnPlateau reducing learning rate to 0.0001250000059371814.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 153ms/step - accuracy: 0.5095 - loss: 1.0021 - val_accuracy: 0.4931 - val_loss: 1.0571 - learning_rate: 2.5000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 156ms/step - accuracy: 0.5196 - loss: 0.9871 - val_accuracy: 0.4844 - val_loss: 1.0602 - learning_rate: 1.2500e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 143ms/step - accuracy: 0.5129 - loss: 0.9894 - val_accuracy: 0.4850 - val_loss: 1.0636 - learning_rate: 1.2500e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.5105 - loss: 0.9903\n",
      "Epoch 15: ReduceLROnPlateau reducing learning rate to 6.25000029685907e-05.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 106ms/step - accuracy: 0.5105 - loss: 0.9903 - val_accuracy: 0.4794 - val_loss: 1.0669 - learning_rate: 1.2500e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 100ms/step - accuracy: 0.5235 - loss: 0.9799 - val_accuracy: 0.4806 - val_loss: 1.0698 - learning_rate: 6.2500e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 119ms/step - accuracy: 0.5250 - loss: 0.9704 - val_accuracy: 0.4769 - val_loss: 1.0731 - learning_rate: 6.2500e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.5143 - loss: 0.9779\n",
      "Epoch 18: ReduceLROnPlateau reducing learning rate to 3.125000148429535e-05.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 128ms/step - accuracy: 0.5144 - loss: 0.9779 - val_accuracy: 0.4769 - val_loss: 1.0755 - learning_rate: 6.2500e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 170ms/step - accuracy: 0.5236 - loss: 0.9713 - val_accuracy: 0.4750 - val_loss: 1.0764 - learning_rate: 3.1250e-05\n",
      "Epoch 20/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 164ms/step - accuracy: 0.5310 - loss: 0.9666 - val_accuracy: 0.4731 - val_loss: 1.0785 - learning_rate: 3.1250e-05\n",
      "Epoch 21/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 145ms/step - accuracy: 0.5299 - loss: 0.9725\n",
      "Epoch 21: ReduceLROnPlateau reducing learning rate to 1.5625000742147677e-05.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 159ms/step - accuracy: 0.5298 - loss: 0.9725 - val_accuracy: 0.4712 - val_loss: 1.0798 - learning_rate: 3.1250e-05\n",
      "Epoch 22/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 113ms/step - accuracy: 0.5391 - loss: 0.9553 - val_accuracy: 0.4731 - val_loss: 1.0802 - learning_rate: 1.5625e-05\n",
      "Epoch 23/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 101ms/step - accuracy: 0.5268 - loss: 0.9720 - val_accuracy: 0.4725 - val_loss: 1.0806 - learning_rate: 1.5625e-05\n",
      "Epoch 24/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.5246 - loss: 0.9751\n",
      "Epoch 24: ReduceLROnPlateau reducing learning rate to 7.812500371073838e-06.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 106ms/step - accuracy: 0.5246 - loss: 0.9751 - val_accuracy: 0.4712 - val_loss: 1.0817 - learning_rate: 1.5625e-05\n",
      "Epoch 25/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 128ms/step - accuracy: 0.5298 - loss: 0.9651 - val_accuracy: 0.4700 - val_loss: 1.0825 - learning_rate: 7.8125e-06\n",
      "Epoch 26/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 89ms/step - accuracy: 0.5340 - loss: 0.9634 - val_accuracy: 0.4694 - val_loss: 1.0825 - learning_rate: 7.8125e-06\n",
      "Epoch 27/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.5340 - loss: 0.9656\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 3.906250185536919e-06.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 51ms/step - accuracy: 0.5340 - loss: 0.9656 - val_accuracy: 0.4681 - val_loss: 1.0831 - learning_rate: 7.8125e-06\n",
      "Epoch 28/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 72ms/step - accuracy: 0.5229 - loss: 0.9786 - val_accuracy: 0.4675 - val_loss: 1.0831 - learning_rate: 3.9063e-06\n",
      "Epoch 29/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 34ms/step - accuracy: 0.5297 - loss: 0.9652 - val_accuracy: 0.4675 - val_loss: 1.0833 - learning_rate: 3.9063e-06\n",
      "Epoch 30/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.5383 - loss: 0.9635\n",
      "Epoch 30: ReduceLROnPlateau reducing learning rate to 1.9531250927684596e-06.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 77ms/step - accuracy: 0.5382 - loss: 0.9636 - val_accuracy: 0.4669 - val_loss: 1.0835 - learning_rate: 3.9063e-06\n",
      "Epoch 31/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 72ms/step - accuracy: 0.5301 - loss: 0.9716 - val_accuracy: 0.4669 - val_loss: 1.0836 - learning_rate: 1.9531e-06\n",
      "Epoch 32/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 102ms/step - accuracy: 0.5228 - loss: 0.9729 - val_accuracy: 0.4675 - val_loss: 1.0836 - learning_rate: 1.9531e-06\n",
      "Epoch 33/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 124ms/step - accuracy: 0.5191 - loss: 0.9733\n",
      "Epoch 33: ReduceLROnPlateau reducing learning rate to 9.765625463842298e-07.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m15s\u001b[0m 145ms/step - accuracy: 0.5192 - loss: 0.9733 - val_accuracy: 0.4681 - val_loss: 1.0837 - learning_rate: 1.9531e-06\n",
      "Epoch 34/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 196ms/step - accuracy: 0.5284 - loss: 0.9670 - val_accuracy: 0.4681 - val_loss: 1.0838 - learning_rate: 9.7656e-07\n",
      "Epoch 35/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 187ms/step - accuracy: 0.5210 - loss: 0.9716 - val_accuracy: 0.4681 - val_loss: 1.0838 - learning_rate: 9.7656e-07\n",
      "Epoch 36/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 160ms/step - accuracy: 0.5283 - loss: 0.9638\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 4.882812731921149e-07.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 183ms/step - accuracy: 0.5283 - loss: 0.9638 - val_accuracy: 0.4681 - val_loss: 1.0838 - learning_rate: 9.7656e-07\n",
      "Epoch 37/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 189ms/step - accuracy: 0.5348 - loss: 0.9640 - val_accuracy: 0.4681 - val_loss: 1.0839 - learning_rate: 4.8828e-07\n",
      "Epoch 38/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 165ms/step - accuracy: 0.5266 - loss: 0.9633 - val_accuracy: 0.4681 - val_loss: 1.0839 - learning_rate: 4.8828e-07\n",
      "Epoch 39/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 126ms/step - accuracy: 0.5306 - loss: 0.9658\n",
      "Epoch 39: ReduceLROnPlateau reducing learning rate to 2.4414063659605745e-07.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 143ms/step - accuracy: 0.5306 - loss: 0.9658 - val_accuracy: 0.4681 - val_loss: 1.0839 - learning_rate: 4.8828e-07\n",
      "Epoch 40/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 161ms/step - accuracy: 0.5257 - loss: 0.9706 - val_accuracy: 0.4681 - val_loss: 1.0839 - learning_rate: 2.4414e-07\n",
      "Epoch 41/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 175ms/step - accuracy: 0.5326 - loss: 0.9670 - val_accuracy: 0.4681 - val_loss: 1.0839 - learning_rate: 2.4414e-07\n",
      "Epoch 42/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 153ms/step - accuracy: 0.5328 - loss: 0.9614\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 1.2207031829802872e-07.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 177ms/step - accuracy: 0.5328 - loss: 0.9614 - val_accuracy: 0.4681 - val_loss: 1.0839 - learning_rate: 2.4414e-07\n",
      "Epoch 43/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 175ms/step - accuracy: 0.5378 - loss: 0.9648 - val_accuracy: 0.4681 - val_loss: 1.0839 - learning_rate: 1.2207e-07\n",
      "Epoch 44/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 159ms/step - accuracy: 0.5127 - loss: 0.9750 - val_accuracy: 0.4681 - val_loss: 1.0840 - learning_rate: 1.2207e-07\n",
      "Epoch 45/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 150ms/step - accuracy: 0.5232 - loss: 0.9707\n",
      "Epoch 45: ReduceLROnPlateau reducing learning rate to 6.103515914901436e-08.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 171ms/step - accuracy: 0.5233 - loss: 0.9707 - val_accuracy: 0.4681 - val_loss: 1.0840 - learning_rate: 1.2207e-07\n",
      "Epoch 46/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 176ms/step - accuracy: 0.5367 - loss: 0.9568 - val_accuracy: 0.4681 - val_loss: 1.0840 - learning_rate: 6.1035e-08\n",
      "Epoch 47/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 129ms/step - accuracy: 0.5384 - loss: 0.9605 - val_accuracy: 0.4681 - val_loss: 1.0840 - learning_rate: 6.1035e-08\n",
      "Epoch 48/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 158ms/step - accuracy: 0.5343 - loss: 0.9576\n",
      "Epoch 48: ReduceLROnPlateau reducing learning rate to 3.051757957450718e-08.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 184ms/step - accuracy: 0.5343 - loss: 0.9576 - val_accuracy: 0.4681 - val_loss: 1.0840 - learning_rate: 6.1035e-08\n",
      "Epoch 49/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 193ms/step - accuracy: 0.5214 - loss: 0.9777 - val_accuracy: 0.4681 - val_loss: 1.0840 - learning_rate: 3.0518e-08\n",
      "Epoch 50/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 201ms/step - accuracy: 0.5383 - loss: 0.9570 - val_accuracy: 0.4681 - val_loss: 1.0840 - learning_rate: 3.0518e-08\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.4769 - loss: 1.0763\n",
      "Test Accuracy: 0.4860\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.callbacks import ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "# 🔹 Assuming df is your original DataFrame\n",
    "# Drop non-numeric + sort by client & time\n",
    "df_sorted = df.sort_values(by=['client_id', 'month'])\n",
    "\n",
    "# 🔹 Drop 'month' (datetime) and keep 'client_id' to group later\n",
    "df_features = df_sorted.drop(columns=['month'])\n",
    "\n",
    "# Encode target if it's categorical\n",
    "if df_features['target'].dtype == 'object':\n",
    "    le = LabelEncoder()\n",
    "    df_features['target'] = le.fit_transform(df_features['target'])\n",
    "\n",
    "# 🔹 Create sequences per client\n",
    "clients = df_features['client_id'].unique()\n",
    "sequence_data = []\n",
    "sequence_labels = []\n",
    "\n",
    "for client in clients:\n",
    "    client_df = df_features[df_features['client_id'] == client].drop(columns=['client_id'])\n",
    "    \n",
    "    if len(client_df) < 3:  # Minimum sequence length\n",
    "        continue\n",
    "    \n",
    "    features = client_df.drop(columns=['target']).values\n",
    "    target = client_df['target'].values[-1]  # Predict final state\n",
    "    \n",
    "    sequence_data.append(features)\n",
    "    sequence_labels.append(target)\n",
    "\n",
    "# Convert to numpy arrays\n",
    "X = np.array(sequence_data)\n",
    "y = np.array(sequence_labels)\n",
    "\n",
    "# 🔹 Scale features across all time steps\n",
    "num_samples, timesteps, num_features = X.shape\n",
    "X_reshaped = X.reshape(-1, num_features)\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_reshaped).reshape(num_samples, timesteps, num_features)\n",
    "\n",
    "# 🔹 Train/Test Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# 🔹 Build LSTM model\n",
    "model = Sequential([\n",
    "    LSTM(128, input_shape=(timesteps, num_features), return_sequences=True),\n",
    "    Dropout(0.3),\n",
    "    LSTM(64),\n",
    "    Dropout(0.3),\n",
    "    Dense(32, activation='relu'),\n",
    "    Dense(len(np.unique(y)), activation='softmax')  # For multi-class\n",
    "])\n",
    "\n",
    "model.compile(optimizer=Adam(learning_rate=0.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# 🔹 Learning rate scheduler\n",
    "lr_scheduler = ReduceLROnPlateau(monitor='val_loss', patience=3, factor=0.5, verbose=1)\n",
    "\n",
    "# 🔹 Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[lr_scheduler]\n",
    ")\n",
    "\n",
    "# 🔹 Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# Initialize and train Logistic Regression\n",
    "logreg = LogisticRegression(max_iter=1000, random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "\n",
    "# Predict\n",
    "y_pred_logreg = logreg.predict(X_test)\n",
    "\n",
    "# Evaluate\n",
    "print(\"📌 Logistic Regression Performance:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_logreg))\n",
    "print(classification_report(y_test, y_pred_logreg))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 28ms/step - accuracy: 0.3633 - loss: 1.3470 - val_accuracy: 0.4787 - val_loss: 1.0495 - learning_rate: 1.0000e-04\n",
      "Epoch 2/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 28ms/step - accuracy: 0.4200 - loss: 1.1217 - val_accuracy: 0.4850 - val_loss: 1.0429 - learning_rate: 1.0000e-04\n",
      "Epoch 3/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.4429 - loss: 1.0848 - val_accuracy: 0.4913 - val_loss: 1.0388 - learning_rate: 1.0000e-04\n",
      "Epoch 4/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.4597 - loss: 1.0666 - val_accuracy: 0.4919 - val_loss: 1.0373 - learning_rate: 1.0000e-04\n",
      "Epoch 5/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.4567 - loss: 1.0575 - val_accuracy: 0.4925 - val_loss: 1.0375 - learning_rate: 1.0000e-04\n",
      "Epoch 6/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.4795 - loss: 1.0570 - val_accuracy: 0.4950 - val_loss: 1.0386 - learning_rate: 1.0000e-04\n",
      "Epoch 7/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.4860 - loss: 1.0455 - val_accuracy: 0.4925 - val_loss: 1.0371 - learning_rate: 1.0000e-04\n",
      "Epoch 8/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 39ms/step - accuracy: 0.4758 - loss: 1.0489 - val_accuracy: 0.4906 - val_loss: 1.0371 - learning_rate: 1.0000e-04\n",
      "Epoch 9/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 40ms/step - accuracy: 0.4827 - loss: 1.0412 - val_accuracy: 0.4913 - val_loss: 1.0369 - learning_rate: 1.0000e-04\n",
      "Epoch 10/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.4856 - loss: 1.0417 - val_accuracy: 0.4925 - val_loss: 1.0379 - learning_rate: 1.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.4817 - loss: 1.0461 - val_accuracy: 0.4919 - val_loss: 1.0382 - learning_rate: 1.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.4826 - loss: 1.0487 - val_accuracy: 0.4919 - val_loss: 1.0366 - learning_rate: 1.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.4945 - loss: 1.0405 - val_accuracy: 0.4931 - val_loss: 1.0372 - learning_rate: 1.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.5022 - loss: 1.0391 - val_accuracy: 0.4925 - val_loss: 1.0392 - learning_rate: 1.0000e-04\n",
      "Epoch 15/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.4951 - loss: 1.0388 - val_accuracy: 0.4925 - val_loss: 1.0370 - learning_rate: 1.0000e-04\n",
      "Epoch 16/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.5027 - loss: 1.0311 - val_accuracy: 0.4925 - val_loss: 1.0369 - learning_rate: 1.0000e-05\n",
      "Epoch 17/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.4970 - loss: 1.0338 - val_accuracy: 0.4925 - val_loss: 1.0368 - learning_rate: 1.0000e-05\n",
      "Epoch 18/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.5027 - loss: 1.0302 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-05\n",
      "Epoch 19/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 45ms/step - accuracy: 0.4999 - loss: 1.0380 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-06\n",
      "Epoch 20/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.4929 - loss: 1.0352 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-06\n",
      "Epoch 21/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.4819 - loss: 1.0429 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-06\n",
      "Epoch 22/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.4899 - loss: 1.0353 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-07\n",
      "Epoch 23/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.5012 - loss: 1.0302 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-07\n",
      "Epoch 24/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.4844 - loss: 1.0401 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-07\n",
      "Epoch 25/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.4942 - loss: 1.0362 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-08\n",
      "Epoch 26/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.4923 - loss: 1.0373 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-08\n",
      "Epoch 27/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.4956 - loss: 1.0415 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-08\n",
      "Epoch 28/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.4904 - loss: 1.0389 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-09\n",
      "Epoch 29/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.4983 - loss: 1.0312 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-09\n",
      "Epoch 30/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.5036 - loss: 1.0243 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-09\n",
      "Epoch 31/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.4964 - loss: 1.0349 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-10\n",
      "Epoch 32/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.4989 - loss: 1.0337 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-10\n",
      "Epoch 33/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.5029 - loss: 1.0249 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-10\n",
      "Epoch 34/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.4974 - loss: 1.0362 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-11\n",
      "Epoch 35/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.5069 - loss: 1.0272 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-11\n",
      "Epoch 36/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.5040 - loss: 1.0269 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-11\n",
      "Epoch 37/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.4982 - loss: 1.0394 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-12\n",
      "Epoch 38/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.4948 - loss: 1.0349 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-12\n",
      "Epoch 39/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.4953 - loss: 1.0375 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-12\n",
      "Epoch 40/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.5122 - loss: 1.0228 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-13\n",
      "Epoch 41/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.5044 - loss: 1.0305 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-13\n",
      "Epoch 42/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.4947 - loss: 1.0359 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-13\n",
      "Epoch 43/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.4833 - loss: 1.0429 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-14\n",
      "Epoch 44/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.5061 - loss: 1.0284 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-14\n",
      "Epoch 45/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.4989 - loss: 1.0369 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-14\n",
      "Epoch 46/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 43ms/step - accuracy: 0.4907 - loss: 1.0341 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-15\n",
      "Epoch 47/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.5017 - loss: 1.0305 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-15\n",
      "Epoch 48/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.4958 - loss: 1.0307 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-15\n",
      "Epoch 49/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 41ms/step - accuracy: 0.4970 - loss: 1.0367 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-16\n",
      "Epoch 50/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.4966 - loss: 1.0350 - val_accuracy: 0.4925 - val_loss: 1.0367 - learning_rate: 1.0000e-16\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.4917 - loss: 1.0417\n",
      "✅ Transformer Test Accuracy: 0.5030\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.layers import Input, Dense, Dropout, LayerNormalization, MultiHeadAttention, GlobalAveragePooling1D\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x = MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    res = x + inputs\n",
    "\n",
    "    x = Dense(ff_dim, activation='relu')(res)\n",
    "    x = Dropout(dropout)(x)\n",
    "    x = Dense(inputs.shape[-1])(x)\n",
    "    x = LayerNormalization(epsilon=1e-6)(x)\n",
    "    return x + res\n",
    "\n",
    "# Build Transformer model\n",
    "input_layer = Input(shape=(timesteps, num_features))\n",
    "x = transformer_encoder(input_layer, head_size=64, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "x = transformer_encoder(x, head_size=64, num_heads=4, ff_dim=128, dropout=0.1)\n",
    "x = GlobalAveragePooling1D()(x)\n",
    "x = Dropout(0.3)(x)\n",
    "x = Dense(64, activation='relu')(x)\n",
    "x = Dropout(0.3)(x)\n",
    "output_layer = Dense(len(np.unique(y)), activation='softmax')(x)\n",
    "\n",
    "model = Model(inputs=input_layer, outputs=output_layer)\n",
    "model.compile(optimizer=Adam(learning_rate=1e-4), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    validation_split=0.2,\n",
    "    callbacks=[ReduceLROnPlateau(monitor='val_loss', patience=3)]\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"✅ Transformer Test Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 30ms/step - accuracy: 0.3166 - loss: 1.1371 - val_accuracy: 0.3419 - val_loss: 1.0964 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.3465 - loss: 1.1006 - val_accuracy: 0.3262 - val_loss: 1.1001 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.3505 - loss: 1.1022 - val_accuracy: 0.2594 - val_loss: 1.1060 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 33ms/step - accuracy: 0.3350 - loss: 1.0961 - val_accuracy: 0.3650 - val_loss: 1.0875 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 32ms/step - accuracy: 0.3488 - loss: 1.0949 - val_accuracy: 0.3269 - val_loss: 1.0970 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 34ms/step - accuracy: 0.3466 - loss: 1.0980 - val_accuracy: 0.2738 - val_loss: 1.1011 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 44ms/step - accuracy: 0.3252 - loss: 1.0982 - val_accuracy: 0.3413 - val_loss: 1.0924 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.3267 - loss: 1.0984 - val_accuracy: 0.3500 - val_loss: 1.0943 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3706 - loss: 1.0934\n",
      "Epoch 9: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 46ms/step - accuracy: 0.3704 - loss: 1.0935 - val_accuracy: 0.2975 - val_loss: 1.1017 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.3120 - loss: 1.0924 - val_accuracy: 0.3025 - val_loss: 1.0976 - learning_rate: 5.0000e-04\n",
      "Epoch 11/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.3224 - loss: 1.0979 - val_accuracy: 0.3150 - val_loss: 1.0971 - learning_rate: 5.0000e-04\n",
      "Epoch 12/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.3404 - loss: 1.0918 - val_accuracy: 0.2975 - val_loss: 1.0986 - learning_rate: 5.0000e-04\n",
      "Epoch 13/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.3356 - loss: 1.0960 - val_accuracy: 0.3187 - val_loss: 1.0964 - learning_rate: 5.0000e-04\n",
      "Epoch 14/50\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.3634 - loss: 1.0891\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 0.0002500000118743628.\n",
      "\u001b[1m100/100\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 47ms/step - accuracy: 0.3632 - loss: 1.0891 - val_accuracy: 0.3131 - val_loss: 1.0992 - learning_rate: 5.0000e-04\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.3733 - loss: 1.0864\n",
      "\n",
      "✅ Transformer Test Accuracy: 0.3680\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.utils import class_weight\n",
    "\n",
    "# === Example data shape ===\n",
    "# X: shape (num_samples, timesteps, num_features)\n",
    "# y: categorical integer labels (e.g., 0 to 5)\n",
    "\n",
    "# Your preloaded data\n",
    "# X, y = ...\n",
    "\n",
    "# === Step 1: Scale features ===\n",
    "num_samples, timesteps, num_features = X.shape\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X.reshape(-1, num_features)).reshape(num_samples, timesteps, num_features)\n",
    "\n",
    "# === Step 2: Train-test split ===\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "# === Step 3: Compute class weights (for imbalanced classes) ===\n",
    "class_weights = class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(y_train), y=y_train)\n",
    "class_weights = dict(enumerate(class_weights))\n",
    "\n",
    "# === Step 4: Model building ===\n",
    "def transformer_encoder(inputs, head_size, num_heads, ff_dim, dropout=0):\n",
    "    x = layers.MultiHeadAttention(key_dim=head_size, num_heads=num_heads, dropout=dropout)(inputs, inputs)\n",
    "    x = layers.Dropout(dropout)(x)\n",
    "    x = layers.LayerNormalization(epsilon=1e-6)(x + inputs)\n",
    "\n",
    "    x_ff = layers.Dense(ff_dim, activation=\"relu\")(x)\n",
    "    x_ff = layers.Dropout(dropout)(x_ff)\n",
    "    x_ff = layers.Dense(inputs.shape[-1])(x_ff)\n",
    "\n",
    "    return layers.LayerNormalization(epsilon=1e-6)(x + x_ff)\n",
    "\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Positional encoding\n",
    "    positions = tf.range(start=0, limit=input_shape[0], delta=1)\n",
    "    pos_embed = layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[1])(positions)\n",
    "    x = inputs + pos_embed\n",
    "\n",
    "    x = transformer_encoder(x, head_size=64, num_heads=4, ff_dim=256, dropout=0.1)\n",
    "    x = transformer_encoder(x, head_size=64, num_heads=4, ff_dim=256, dropout=0.1)\n",
    "\n",
    "    x = layers.GlobalAveragePooling1D()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# === Step 5: Compile and train ===\n",
    "num_classes = len(np.unique(y_train))\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = build_model(input_shape, num_classes)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-6, verbose=1)\n",
    "early_stop = callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_split=0.2,\n",
    "    epochs=50,\n",
    "    batch_size=64,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=[lr_scheduler, early_stop]\n",
    ")\n",
    "\n",
    "# === Step 6: Evaluate ===\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test)\n",
    "print(f\"\\n✅ Transformer Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['client_id', 'month', 'portfolio_value', 'equity_allocation_pct',\n",
      "       'fixed_income_allocation_pct', 'monthly_contribution',\n",
      "       'market_volatility_index', 'macroeconomic_score', 'sentiment_index',\n",
      "       'age', 'employment_status', 'annual_income', 'debt_to_income_ratio',\n",
      "       'financial_knowledge_score', 'risk_appetite',\n",
      "       'investment_horizon_years', 'savings_rate', 'net_worth',\n",
      "       'recommended_strategy'],\n",
      "      dtype='object')\n",
      "Epoch 1/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 3ms/step - accuracy: 0.4979 - loss: 1.0313 - val_accuracy: 0.5046 - val_loss: 1.0189 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 4ms/step - accuracy: 0.5024 - loss: 1.0179 - val_accuracy: 0.5108 - val_loss: 1.0063 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.5131 - loss: 0.9985 - val_accuracy: 0.5233 - val_loss: 0.9870 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 9ms/step - accuracy: 0.5243 - loss: 0.9785 - val_accuracy: 0.5375 - val_loss: 0.9649 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.5386 - loss: 0.9547 - val_accuracy: 0.5493 - val_loss: 0.9442 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.5504 - loss: 0.9372 - val_accuracy: 0.5579 - val_loss: 0.9214 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.5598 - loss: 0.9209 - val_accuracy: 0.5563 - val_loss: 0.9241 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.5678 - loss: 0.9082 - val_accuracy: 0.5696 - val_loss: 0.9104 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.5750 - loss: 0.8964 - val_accuracy: 0.5788 - val_loss: 0.8904 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.5799 - loss: 0.8887 - val_accuracy: 0.5830 - val_loss: 0.8865 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m51s\u001b[0m 6ms/step - accuracy: 0.5862 - loss: 0.8779 - val_accuracy: 0.5911 - val_loss: 0.8753 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - accuracy: 0.5905 - loss: 0.8716 - val_accuracy: 0.5882 - val_loss: 0.8687 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.5935 - loss: 0.8637 - val_accuracy: 0.5985 - val_loss: 0.8591 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.5970 - loss: 0.8566 - val_accuracy: 0.5993 - val_loss: 0.8565 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - accuracy: 0.5995 - loss: 0.8514 - val_accuracy: 0.5977 - val_loss: 0.8572 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - accuracy: 0.6038 - loss: 0.8465 - val_accuracy: 0.6085 - val_loss: 0.8448 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.6067 - loss: 0.8435 - val_accuracy: 0.6004 - val_loss: 0.8474 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.6078 - loss: 0.8397 - val_accuracy: 0.6052 - val_loss: 0.8437 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - accuracy: 0.6119 - loss: 0.8349 - val_accuracy: 0.6118 - val_loss: 0.8377 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - accuracy: 0.6122 - loss: 0.8326 - val_accuracy: 0.6021 - val_loss: 0.8457 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 6ms/step - accuracy: 0.6156 - loss: 0.8276 - val_accuracy: 0.6081 - val_loss: 0.8423 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.6160 - loss: 0.8269 - val_accuracy: 0.6140 - val_loss: 0.8260 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.6173 - loss: 0.8240 - val_accuracy: 0.6074 - val_loss: 0.8341 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.6175 - loss: 0.8207 - val_accuracy: 0.6224 - val_loss: 0.8208 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.6216 - loss: 0.8163 - val_accuracy: 0.6213 - val_loss: 0.8189 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.6230 - loss: 0.8143 - val_accuracy: 0.6171 - val_loss: 0.8230 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 6ms/step - accuracy: 0.6242 - loss: 0.8122 - val_accuracy: 0.6189 - val_loss: 0.8239 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 6ms/step - accuracy: 0.6256 - loss: 0.8072 - val_accuracy: 0.6199 - val_loss: 0.8213 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.6258 - loss: 0.8087 - val_accuracy: 0.6185 - val_loss: 0.8144 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 6ms/step - accuracy: 0.6267 - loss: 0.8057 - val_accuracy: 0.6268 - val_loss: 0.8116 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.6306 - loss: 0.8021 - val_accuracy: 0.6207 - val_loss: 0.8158 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.6316 - loss: 0.7995 - val_accuracy: 0.6318 - val_loss: 0.8049 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.6328 - loss: 0.7966 - val_accuracy: 0.6226 - val_loss: 0.8074 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.6340 - loss: 0.7938 - val_accuracy: 0.6289 - val_loss: 0.8122 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.6347 - loss: 0.7913 - val_accuracy: 0.6330 - val_loss: 0.7965 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.6368 - loss: 0.7890 - val_accuracy: 0.6346 - val_loss: 0.7988 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 6ms/step - accuracy: 0.6358 - loss: 0.7884 - val_accuracy: 0.6355 - val_loss: 0.7856 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 6ms/step - accuracy: 0.6391 - loss: 0.7847 - val_accuracy: 0.6215 - val_loss: 0.8027 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.6397 - loss: 0.7849 - val_accuracy: 0.6308 - val_loss: 0.7995 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.6402 - loss: 0.7840 - val_accuracy: 0.6348 - val_loss: 0.7907 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.6401 - loss: 0.7810 - val_accuracy: 0.6363 - val_loss: 0.7916 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.6419 - loss: 0.7789\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 0.0005000000237487257.\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.6419 - loss: 0.7789 - val_accuracy: 0.6335 - val_loss: 0.7947 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.6567 - loss: 0.7530 - val_accuracy: 0.6550 - val_loss: 0.7562 - learning_rate: 5.0000e-04\n",
      "Epoch 44/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.6607 - loss: 0.7458 - val_accuracy: 0.6563 - val_loss: 0.7574 - learning_rate: 5.0000e-04\n",
      "Epoch 45/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - accuracy: 0.6605 - loss: 0.7440 - val_accuracy: 0.6590 - val_loss: 0.7532 - learning_rate: 5.0000e-04\n",
      "Epoch 46/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.6626 - loss: 0.7437 - val_accuracy: 0.6597 - val_loss: 0.7493 - learning_rate: 5.0000e-04\n",
      "Epoch 47/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.6627 - loss: 0.7407 - val_accuracy: 0.6537 - val_loss: 0.7560 - learning_rate: 5.0000e-04\n",
      "Epoch 48/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 6ms/step - accuracy: 0.6653 - loss: 0.7397 - val_accuracy: 0.6547 - val_loss: 0.7542 - learning_rate: 5.0000e-04\n",
      "Epoch 49/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.6637 - loss: 0.7376 - val_accuracy: 0.6572 - val_loss: 0.7503 - learning_rate: 5.0000e-04\n",
      "Epoch 50/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.6625 - loss: 0.7385 - val_accuracy: 0.6587 - val_loss: 0.7468 - learning_rate: 5.0000e-04\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.6563 - loss: 0.7527\n",
      "\n",
      "✅ Transformer Test Accuracy: 0.6587\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load your dataset\n",
    "df = pd.read_csv(\"datasets/classification_data.csv\")\n",
    "\n",
    "# Inspect columns and identify the label column\n",
    "print(df.columns)  # Check and replace the label column below accordingly\n",
    "label_col = 'recommended_strategy'  \n",
    "\n",
    "# Encode label\n",
    "y = LabelEncoder().fit_transform(df[label_col])\n",
    "X = df.drop(columns=[label_col])\n",
    "\n",
    "# Drop non-numeric or ID columns if necessary\n",
    "X = X.select_dtypes(include=[np.number])  # keep only numerical features\n",
    "\n",
    "# Fill any missing values\n",
    "X = X.fillna(X.mean())\n",
    "\n",
    "# Scale the features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape input for Transformer: (samples, timesteps, features)\n",
    "# We'll treat each row as a sequence of 1 step with many features\n",
    "X_reshaped = X_scaled.reshape(X_scaled.shape[0], 1, X_scaled.shape[1])\n",
    "\n",
    "# Train/validation/test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_reshaped, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build Transformer model\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Positional encoding\n",
    "    positions = tf.range(start=0, limit=input_shape[0], delta=1)\n",
    "    pos_embed = layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[1])(positions)\n",
    "    x = inputs + pos_embed\n",
    "\n",
    "    # Transformer encoder block\n",
    "    attention = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "    x = layers.Add()([x, attention])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "\n",
    "    ffn = layers.Dense(64, activation=\"relu\")(x)\n",
    "    ffn = layers.Dense(input_shape[1])(ffn)\n",
    "    x = layers.Add()([x, ffn])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Prepare model\n",
    "num_classes = len(np.unique(y))\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = build_model(input_shape, num_classes)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-6, verbose=1)\n",
    "early_stop = callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[lr_scheduler, early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"\\n✅ Transformer Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 7ms/step - accuracy: 0.4984 - loss: 1.0297 - val_accuracy: 0.5065 - val_loss: 1.0106 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 7ms/step - accuracy: 0.5140 - loss: 0.9960 - val_accuracy: 0.5303 - val_loss: 0.9649 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 7ms/step - accuracy: 0.5414 - loss: 0.9507 - val_accuracy: 0.5579 - val_loss: 0.9226 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 7ms/step - accuracy: 0.5682 - loss: 0.9120 - val_accuracy: 0.5829 - val_loss: 0.8938 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 7ms/step - accuracy: 0.5894 - loss: 0.8795 - val_accuracy: 0.5921 - val_loss: 0.8832 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 7ms/step - accuracy: 0.6043 - loss: 0.8557 - val_accuracy: 0.6081 - val_loss: 0.8477 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 6ms/step - accuracy: 0.6201 - loss: 0.8326 - val_accuracy: 0.6236 - val_loss: 0.8302 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 7ms/step - accuracy: 0.6258 - loss: 0.8178 - val_accuracy: 0.6274 - val_loss: 0.8199 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 7ms/step - accuracy: 0.6369 - loss: 0.8009 - val_accuracy: 0.6363 - val_loss: 0.8070 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 6ms/step - accuracy: 0.6445 - loss: 0.7892 - val_accuracy: 0.6456 - val_loss: 0.7895 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 6ms/step - accuracy: 0.6500 - loss: 0.7794 - val_accuracy: 0.6532 - val_loss: 0.7792 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 7ms/step - accuracy: 0.6557 - loss: 0.7662 - val_accuracy: 0.6472 - val_loss: 0.7852 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 7ms/step - accuracy: 0.6614 - loss: 0.7582 - val_accuracy: 0.6642 - val_loss: 0.7585 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.6655 - loss: 0.7499 - val_accuracy: 0.6594 - val_loss: 0.7614 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.6654 - loss: 0.7491 - val_accuracy: 0.6615 - val_loss: 0.7568 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.6718 - loss: 0.7401 - val_accuracy: 0.6607 - val_loss: 0.7593 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.6740 - loss: 0.7341 - val_accuracy: 0.6673 - val_loss: 0.7458 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.6781 - loss: 0.7287 - val_accuracy: 0.6679 - val_loss: 0.7489 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.6794 - loss: 0.7265 - val_accuracy: 0.6717 - val_loss: 0.7422 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 6ms/step - accuracy: 0.6808 - loss: 0.7232 - val_accuracy: 0.6756 - val_loss: 0.7361 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m49s\u001b[0m 6ms/step - accuracy: 0.6851 - loss: 0.7176 - val_accuracy: 0.6719 - val_loss: 0.7462 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 6ms/step - accuracy: 0.6841 - loss: 0.7187 - val_accuracy: 0.6780 - val_loss: 0.7342 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 7ms/step - accuracy: 0.6889 - loss: 0.7115 - val_accuracy: 0.6705 - val_loss: 0.7360 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 7ms/step - accuracy: 0.6884 - loss: 0.7109 - val_accuracy: 0.6834 - val_loss: 0.7275 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m89s\u001b[0m 11ms/step - accuracy: 0.6914 - loss: 0.7072 - val_accuracy: 0.6851 - val_loss: 0.7213 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - accuracy: 0.6922 - loss: 0.7051 - val_accuracy: 0.6804 - val_loss: 0.7262 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m42s\u001b[0m 5ms/step - accuracy: 0.6930 - loss: 0.7020 - val_accuracy: 0.6844 - val_loss: 0.7207 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.6932 - loss: 0.7041 - val_accuracy: 0.6867 - val_loss: 0.7144 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 6ms/step - accuracy: 0.6952 - loss: 0.6995 - val_accuracy: 0.6884 - val_loss: 0.7182 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.6992 - loss: 0.6953 - val_accuracy: 0.6829 - val_loss: 0.7221 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 6ms/step - accuracy: 0.6946 - loss: 0.6977 - val_accuracy: 0.6852 - val_loss: 0.7243 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 5ms/step - accuracy: 0.6963 - loss: 0.6964 - val_accuracy: 0.6839 - val_loss: 0.7188 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.6967 - loss: 0.6917 - val_accuracy: 0.6867 - val_loss: 0.7094 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m45s\u001b[0m 6ms/step - accuracy: 0.6977 - loss: 0.6935 - val_accuracy: 0.6915 - val_loss: 0.7071 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.6979 - loss: 0.6910 - val_accuracy: 0.6839 - val_loss: 0.7147 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.7013 - loss: 0.6882 - val_accuracy: 0.6966 - val_loss: 0.7014 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.7022 - loss: 0.6872 - val_accuracy: 0.6927 - val_loss: 0.7046 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.7025 - loss: 0.6833 - val_accuracy: 0.6961 - val_loss: 0.7018 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.7026 - loss: 0.6842 - val_accuracy: 0.6952 - val_loss: 0.6981 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.7010 - loss: 0.6848 - val_accuracy: 0.6886 - val_loss: 0.7061 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 6ms/step - accuracy: 0.7048 - loss: 0.6800 - val_accuracy: 0.6947 - val_loss: 0.7034 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 6ms/step - accuracy: 0.7068 - loss: 0.6751 - val_accuracy: 0.6888 - val_loss: 0.7089 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.7039 - loss: 0.6785 - val_accuracy: 0.6938 - val_loss: 0.6956 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.7038 - loss: 0.6777 - val_accuracy: 0.6936 - val_loss: 0.7010 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m41s\u001b[0m 5ms/step - accuracy: 0.7064 - loss: 0.6765 - val_accuracy: 0.6989 - val_loss: 0.6887 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.7049 - loss: 0.6751 - val_accuracy: 0.6957 - val_loss: 0.6952 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 5ms/step - accuracy: 0.7057 - loss: 0.6749 - val_accuracy: 0.6950 - val_loss: 0.6960 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.7050 - loss: 0.6739 - val_accuracy: 0.6961 - val_loss: 0.6910 - learning_rate: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.7080 - loss: 0.6708 - val_accuracy: 0.6987 - val_loss: 0.6925 - learning_rate: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.7081 - loss: 0.6694 - val_accuracy: 0.7026 - val_loss: 0.6867 - learning_rate: 0.0010\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 3ms/step - accuracy: 0.7041 - loss: 0.6829\n",
      "\n",
      "✅ Transformer Test Accuracy: 0.7027\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"datasets/classification_data.csv\")\n",
    "\n",
    "# Label column\n",
    "label_col = 'recommended_strategy'\n",
    "y = LabelEncoder().fit_transform(df[label_col])\n",
    "\n",
    "# Drop ID and label columns\n",
    "X = df.drop(columns=['client_id', label_col])\n",
    "\n",
    "# Handle 'month' column if it exists\n",
    "if 'month' in X.columns:\n",
    "    X['month'] = pd.to_datetime(X['month'], errors='coerce')  # Convert to datetime\n",
    "    X['month_num'] = X['month'].dt.month\n",
    "    X['year'] = X['month'].dt.year\n",
    "    X = X.drop(columns=['month'])\n",
    "\n",
    "# Encode all categorical columns\n",
    "for col in X.select_dtypes(include='object').columns:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
    "\n",
    "# Fill missing values\n",
    "X = X.fillna(X.mean(numeric_only=True))\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape for Transformer: (samples, timesteps=1, features)\n",
    "X_reshaped = X_scaled.reshape(X_scaled.shape[0], 1, X_scaled.shape[1])\n",
    "\n",
    "# Train/val/test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_reshaped, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build Transformer model\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Positional encoding\n",
    "    positions = tf.range(start=0, limit=input_shape[0], delta=1)\n",
    "    pos_embed = layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[1])(positions)\n",
    "    x = inputs + pos_embed\n",
    "\n",
    "    # Transformer encoder\n",
    "    attention = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "    x = layers.Add()([x, attention])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "\n",
    "    ffn = layers.Dense(64, activation=\"relu\")(x)\n",
    "    ffn = layers.Dense(input_shape[1])(ffn)\n",
    "    x = layers.Add()([x, ffn])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Model prep\n",
    "num_classes = len(np.unique(y))\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = build_model(input_shape, num_classes)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-6, verbose=1)\n",
    "early_stop = callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[lr_scheduler, early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"\\n✅ Transformer Test Accuracy: {test_acc:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 7ms/step - accuracy: 0.4968 - loss: 1.0347 - val_accuracy: 0.5049 - val_loss: 1.0232 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 6ms/step - accuracy: 0.5065 - loss: 1.0206 - val_accuracy: 0.5079 - val_loss: 1.0123 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 7ms/step - accuracy: 0.5077 - loss: 1.0136 - val_accuracy: 0.5155 - val_loss: 1.0006 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 7ms/step - accuracy: 0.5137 - loss: 1.0039 - val_accuracy: 0.5204 - val_loss: 0.9899 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 7ms/step - accuracy: 0.5165 - loss: 0.9961 - val_accuracy: 0.5254 - val_loss: 0.9764 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m48s\u001b[0m 6ms/step - accuracy: 0.5212 - loss: 0.9872 - val_accuracy: 0.5282 - val_loss: 0.9666 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.5240 - loss: 0.9784 - val_accuracy: 0.5372 - val_loss: 0.9525 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 6ms/step - accuracy: 0.5279 - loss: 0.9725 - val_accuracy: 0.5394 - val_loss: 0.9444 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 7ms/step - accuracy: 0.5309 - loss: 0.9659 - val_accuracy: 0.5441 - val_loss: 0.9386 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 7ms/step - accuracy: 0.5338 - loss: 0.9602 - val_accuracy: 0.5478 - val_loss: 0.9300 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 7ms/step - accuracy: 0.5374 - loss: 0.9541 - val_accuracy: 0.5514 - val_loss: 0.9235 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 7ms/step - accuracy: 0.5366 - loss: 0.9523 - val_accuracy: 0.5541 - val_loss: 0.9163 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 7ms/step - accuracy: 0.5387 - loss: 0.9486 - val_accuracy: 0.5573 - val_loss: 0.9071 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 7ms/step - accuracy: 0.5415 - loss: 0.9441 - val_accuracy: 0.5587 - val_loss: 0.9075 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 7ms/step - accuracy: 0.5424 - loss: 0.9417 - val_accuracy: 0.5618 - val_loss: 0.9030 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 7ms/step - accuracy: 0.5448 - loss: 0.9370 - val_accuracy: 0.5655 - val_loss: 0.9022 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m63s\u001b[0m 8ms/step - accuracy: 0.5459 - loss: 0.9363 - val_accuracy: 0.5704 - val_loss: 0.8920 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m61s\u001b[0m 8ms/step - accuracy: 0.5501 - loss: 0.9312 - val_accuracy: 0.5693 - val_loss: 0.8874 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 8ms/step - accuracy: 0.5503 - loss: 0.9298 - val_accuracy: 0.5774 - val_loss: 0.8813 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 7ms/step - accuracy: 0.5522 - loss: 0.9272 - val_accuracy: 0.5763 - val_loss: 0.8841 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 7ms/step - accuracy: 0.5514 - loss: 0.9262 - val_accuracy: 0.5759 - val_loss: 0.8825 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 7ms/step - accuracy: 0.5539 - loss: 0.9232 - val_accuracy: 0.5827 - val_loss: 0.8722 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 7ms/step - accuracy: 0.5552 - loss: 0.9197 - val_accuracy: 0.5818 - val_loss: 0.8664 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m54s\u001b[0m 7ms/step - accuracy: 0.5550 - loss: 0.9211 - val_accuracy: 0.5748 - val_loss: 0.8811 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m53s\u001b[0m 7ms/step - accuracy: 0.5589 - loss: 0.9146 - val_accuracy: 0.5873 - val_loss: 0.8616 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 7ms/step - accuracy: 0.5581 - loss: 0.9172 - val_accuracy: 0.5886 - val_loss: 0.8636 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 7ms/step - accuracy: 0.5564 - loss: 0.9154 - val_accuracy: 0.5914 - val_loss: 0.8482 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 7ms/step - accuracy: 0.5584 - loss: 0.9139 - val_accuracy: 0.5911 - val_loss: 0.8558 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m52s\u001b[0m 7ms/step - accuracy: 0.5603 - loss: 0.9131 - val_accuracy: 0.5955 - val_loss: 0.8497 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m50s\u001b[0m 6ms/step - accuracy: 0.5610 - loss: 0.9114 - val_accuracy: 0.5937 - val_loss: 0.8488 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1170s\u001b[0m 149ms/step - accuracy: 0.5619 - loss: 0.9092 - val_accuracy: 0.5952 - val_loss: 0.8487 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m62s\u001b[0m 8ms/step - accuracy: 0.5636 - loss: 0.9061 - val_accuracy: 0.5939 - val_loss: 0.8427 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m60s\u001b[0m 8ms/step - accuracy: 0.5628 - loss: 0.9064 - val_accuracy: 0.5970 - val_loss: 0.8461 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 9ms/step - accuracy: 0.5637 - loss: 0.9054 - val_accuracy: 0.5945 - val_loss: 0.8502 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 9ms/step - accuracy: 0.5634 - loss: 0.9060 - val_accuracy: 0.5927 - val_loss: 0.8506 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 9ms/step - accuracy: 0.5661 - loss: 0.9019 - val_accuracy: 0.5945 - val_loss: 0.8427 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m68s\u001b[0m 9ms/step - accuracy: 0.5650 - loss: 0.9023 - val_accuracy: 0.6017 - val_loss: 0.8337 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m73s\u001b[0m 9ms/step - accuracy: 0.5672 - loss: 0.9007 - val_accuracy: 0.6006 - val_loss: 0.8389 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 9ms/step - accuracy: 0.5670 - loss: 0.8990 - val_accuracy: 0.6025 - val_loss: 0.8414 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 9ms/step - accuracy: 0.5692 - loss: 0.8991 - val_accuracy: 0.5974 - val_loss: 0.8432 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 9ms/step - accuracy: 0.5694 - loss: 0.8984 - val_accuracy: 0.6043 - val_loss: 0.8318 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m75s\u001b[0m 10ms/step - accuracy: 0.5697 - loss: 0.8963 - val_accuracy: 0.5953 - val_loss: 0.8406 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m72s\u001b[0m 9ms/step - accuracy: 0.5693 - loss: 0.8972 - val_accuracy: 0.6033 - val_loss: 0.8377 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 8ms/step - accuracy: 0.5692 - loss: 0.8968 - val_accuracy: 0.6063 - val_loss: 0.8246 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m70s\u001b[0m 9ms/step - accuracy: 0.5698 - loss: 0.8955 - val_accuracy: 0.6060 - val_loss: 0.8317 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m71s\u001b[0m 9ms/step - accuracy: 0.5713 - loss: 0.8929 - val_accuracy: 0.6038 - val_loss: 0.8252 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 7ms/step - accuracy: 0.5702 - loss: 0.8930 - val_accuracy: 0.6055 - val_loss: 0.8221 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 7ms/step - accuracy: 0.5700 - loss: 0.8945 - val_accuracy: 0.6084 - val_loss: 0.8266 - learning_rate: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m55s\u001b[0m 7ms/step - accuracy: 0.5711 - loss: 0.8923 - val_accuracy: 0.6011 - val_loss: 0.8320 - learning_rate: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m58s\u001b[0m 7ms/step - accuracy: 0.5714 - loss: 0.8909 - val_accuracy: 0.6049 - val_loss: 0.8284 - learning_rate: 0.0010\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step - accuracy: 0.6040 - loss: 0.8237\n",
      "\n",
      "✅ Tuned Transformer Test Accuracy: 0.6040\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"datasets/classification_data.csv\")\n",
    "\n",
    "# Label encode target\n",
    "label_col = 'recommended_strategy'\n",
    "y = LabelEncoder().fit_transform(df[label_col])\n",
    "\n",
    "# Drop ID and label columns\n",
    "X = df.drop(columns=['client_id', label_col])\n",
    "\n",
    "# Handle 'month' column if exists\n",
    "if 'month' in X.columns:\n",
    "    X['month'] = pd.to_datetime(X['month'], errors='coerce')\n",
    "    X['month_num'] = X['month'].dt.month\n",
    "    X['year'] = X['month'].dt.year\n",
    "    X = X.drop(columns=['month'])\n",
    "\n",
    "# Encode categorical string columns\n",
    "for col in X.select_dtypes(include='object').columns:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
    "\n",
    "# Fill missing values\n",
    "X = X.fillna(X.mean(numeric_only=True))\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape for Transformer: (samples, timesteps=1, features)\n",
    "X_reshaped = X_scaled.reshape(X_scaled.shape[0], 1, X_scaled.shape[1])\n",
    "\n",
    "# Train/val/test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_reshaped, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build tuned Transformer model\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Positional Encoding\n",
    "    positions = tf.range(start=0, limit=input_shape[0], delta=1)\n",
    "    pos_embed = layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[1])(positions)\n",
    "    x = inputs + pos_embed\n",
    "\n",
    "    # Transformer Encoder Block\n",
    "    attention = layers.MultiHeadAttention(num_heads=8, key_dim=64)(x, x)\n",
    "    x = layers.Add()([x, attention])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "\n",
    "    ffn = layers.Dense(128, activation=\"relu\")(x)\n",
    "    ffn = layers.Dropout(0.3)(ffn)\n",
    "    ffn = layers.Dense(input_shape[1])(ffn)\n",
    "    x = layers.Add()([x, ffn])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "\n",
    "    # Output Layers\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(128, activation=\"relu\")(x)\n",
    "    x = layers.Dropout(0.3)(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Prepare model\n",
    "num_classes = len(np.unique(y))\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = build_model(input_shape, num_classes)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-6, verbose=1)\n",
    "early_stop = callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[lr_scheduler, early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"\\n✅ Tuned Transformer Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m199s\u001b[0m 24ms/step - accuracy: 0.4999 - loss: 1.0268 - val_accuracy: 0.5084 - val_loss: 1.0011 - learning_rate: 0.0010\n",
      "Epoch 2/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 17ms/step - accuracy: 0.5248 - loss: 0.9808 - val_accuracy: 0.5519 - val_loss: 0.9382 - learning_rate: 0.0010\n",
      "Epoch 3/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m126s\u001b[0m 16ms/step - accuracy: 0.5647 - loss: 0.9175 - val_accuracy: 0.5903 - val_loss: 0.8844 - learning_rate: 0.0010\n",
      "Epoch 4/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m161s\u001b[0m 20ms/step - accuracy: 0.5995 - loss: 0.8624 - val_accuracy: 0.6146 - val_loss: 0.8441 - learning_rate: 0.0010\n",
      "Epoch 5/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m136s\u001b[0m 17ms/step - accuracy: 0.6253 - loss: 0.8200 - val_accuracy: 0.6337 - val_loss: 0.7954 - learning_rate: 0.0010\n",
      "Epoch 6/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m100s\u001b[0m 13ms/step - accuracy: 0.6431 - loss: 0.7826 - val_accuracy: 0.6496 - val_loss: 0.7713 - learning_rate: 0.0010\n",
      "Epoch 7/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 8ms/step - accuracy: 0.6575 - loss: 0.7589 - val_accuracy: 0.6574 - val_loss: 0.7544 - learning_rate: 0.0010\n",
      "Epoch 8/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m43s\u001b[0m 6ms/step - accuracy: 0.6655 - loss: 0.7387 - val_accuracy: 0.6746 - val_loss: 0.7237 - learning_rate: 0.0010\n",
      "Epoch 9/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 6ms/step - accuracy: 0.6774 - loss: 0.7191 - val_accuracy: 0.6848 - val_loss: 0.7045 - learning_rate: 0.0010\n",
      "Epoch 10/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m44s\u001b[0m 6ms/step - accuracy: 0.6833 - loss: 0.7030 - val_accuracy: 0.6899 - val_loss: 0.6998 - learning_rate: 0.0010\n",
      "Epoch 11/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.6908 - loss: 0.6883 - val_accuracy: 0.6906 - val_loss: 0.6926 - learning_rate: 0.0010\n",
      "Epoch 12/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.6980 - loss: 0.6788 - val_accuracy: 0.7033 - val_loss: 0.6664 - learning_rate: 0.0010\n",
      "Epoch 13/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.7016 - loss: 0.6672 - val_accuracy: 0.7021 - val_loss: 0.6750 - learning_rate: 0.0010\n",
      "Epoch 14/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.7087 - loss: 0.6588 - val_accuracy: 0.7138 - val_loss: 0.6543 - learning_rate: 0.0010\n",
      "Epoch 15/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.7142 - loss: 0.6487 - val_accuracy: 0.7172 - val_loss: 0.6471 - learning_rate: 0.0010\n",
      "Epoch 16/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.7197 - loss: 0.6380 - val_accuracy: 0.7169 - val_loss: 0.6399 - learning_rate: 0.0010\n",
      "Epoch 17/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.7214 - loss: 0.6324 - val_accuracy: 0.7233 - val_loss: 0.6360 - learning_rate: 0.0010\n",
      "Epoch 18/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m37s\u001b[0m 5ms/step - accuracy: 0.7271 - loss: 0.6239 - val_accuracy: 0.7233 - val_loss: 0.6276 - learning_rate: 0.0010\n",
      "Epoch 19/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.7279 - loss: 0.6197 - val_accuracy: 0.7261 - val_loss: 0.6276 - learning_rate: 0.0010\n",
      "Epoch 20/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.7323 - loss: 0.6142 - val_accuracy: 0.7227 - val_loss: 0.6272 - learning_rate: 0.0010\n",
      "Epoch 21/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.7349 - loss: 0.6083 - val_accuracy: 0.7281 - val_loss: 0.6189 - learning_rate: 0.0010\n",
      "Epoch 22/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.7373 - loss: 0.6037 - val_accuracy: 0.7334 - val_loss: 0.6090 - learning_rate: 0.0010\n",
      "Epoch 23/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.7402 - loss: 0.5991 - val_accuracy: 0.7363 - val_loss: 0.6065 - learning_rate: 0.0010\n",
      "Epoch 24/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m46s\u001b[0m 6ms/step - accuracy: 0.7395 - loss: 0.5973 - val_accuracy: 0.7408 - val_loss: 0.6006 - learning_rate: 0.0010\n",
      "Epoch 25/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 5ms/step - accuracy: 0.7446 - loss: 0.5889 - val_accuracy: 0.7377 - val_loss: 0.5989 - learning_rate: 0.0010\n",
      "Epoch 26/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.7448 - loss: 0.5863 - val_accuracy: 0.7445 - val_loss: 0.5875 - learning_rate: 0.0010\n",
      "Epoch 27/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.7455 - loss: 0.5834 - val_accuracy: 0.7422 - val_loss: 0.5882 - learning_rate: 0.0010\n",
      "Epoch 28/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.7484 - loss: 0.5800 - val_accuracy: 0.7457 - val_loss: 0.5872 - learning_rate: 0.0010\n",
      "Epoch 29/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m39s\u001b[0m 5ms/step - accuracy: 0.7494 - loss: 0.5772 - val_accuracy: 0.7457 - val_loss: 0.5851 - learning_rate: 0.0010\n",
      "Epoch 30/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.7491 - loss: 0.5778 - val_accuracy: 0.7447 - val_loss: 0.5846 - learning_rate: 0.0010\n",
      "Epoch 31/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.7515 - loss: 0.5720 - val_accuracy: 0.7482 - val_loss: 0.5798 - learning_rate: 0.0010\n",
      "Epoch 32/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.7541 - loss: 0.5698 - val_accuracy: 0.7527 - val_loss: 0.5762 - learning_rate: 0.0010\n",
      "Epoch 33/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m38s\u001b[0m 5ms/step - accuracy: 0.7564 - loss: 0.5648 - val_accuracy: 0.7539 - val_loss: 0.5696 - learning_rate: 0.0010\n",
      "Epoch 34/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m56s\u001b[0m 7ms/step - accuracy: 0.7569 - loss: 0.5626 - val_accuracy: 0.7520 - val_loss: 0.5688 - learning_rate: 0.0010\n",
      "Epoch 35/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m29s\u001b[0m 4ms/step - accuracy: 0.7554 - loss: 0.5628 - val_accuracy: 0.7514 - val_loss: 0.5758 - learning_rate: 0.0010\n",
      "Epoch 36/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m34s\u001b[0m 4ms/step - accuracy: 0.7593 - loss: 0.5594 - val_accuracy: 0.7570 - val_loss: 0.5574 - learning_rate: 0.0010\n",
      "Epoch 37/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m69s\u001b[0m 9ms/step - accuracy: 0.7600 - loss: 0.5571 - val_accuracy: 0.7525 - val_loss: 0.5701 - learning_rate: 0.0010\n",
      "Epoch 38/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m93s\u001b[0m 10ms/step - accuracy: 0.7580 - loss: 0.5550 - val_accuracy: 0.7543 - val_loss: 0.5647 - learning_rate: 0.0010\n",
      "Epoch 39/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m80s\u001b[0m 10ms/step - accuracy: 0.7604 - loss: 0.5534 - val_accuracy: 0.7593 - val_loss: 0.5570 - learning_rate: 0.0010\n",
      "Epoch 40/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m47s\u001b[0m 6ms/step - accuracy: 0.7607 - loss: 0.5525 - val_accuracy: 0.7602 - val_loss: 0.5586 - learning_rate: 0.0010\n",
      "Epoch 41/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m28s\u001b[0m 4ms/step - accuracy: 0.7611 - loss: 0.5499 - val_accuracy: 0.7597 - val_loss: 0.5513 - learning_rate: 0.0010\n",
      "Epoch 42/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4ms/step - accuracy: 0.7639 - loss: 0.5466 - val_accuracy: 0.7597 - val_loss: 0.5510 - learning_rate: 0.0010\n",
      "Epoch 43/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4ms/step - accuracy: 0.7651 - loss: 0.5417 - val_accuracy: 0.7656 - val_loss: 0.5437 - learning_rate: 0.0010\n",
      "Epoch 44/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4ms/step - accuracy: 0.7666 - loss: 0.5386 - val_accuracy: 0.7605 - val_loss: 0.5504 - learning_rate: 0.0010\n",
      "Epoch 45/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4ms/step - accuracy: 0.7673 - loss: 0.5376 - val_accuracy: 0.7671 - val_loss: 0.5393 - learning_rate: 0.0010\n",
      "Epoch 46/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4ms/step - accuracy: 0.7668 - loss: 0.5366 - val_accuracy: 0.7621 - val_loss: 0.5465 - learning_rate: 0.0010\n",
      "Epoch 47/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4ms/step - accuracy: 0.7674 - loss: 0.5362 - val_accuracy: 0.7605 - val_loss: 0.5519 - learning_rate: 0.0010\n",
      "Epoch 48/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4ms/step - accuracy: 0.7690 - loss: 0.5338 - val_accuracy: 0.7712 - val_loss: 0.5320 - learning_rate: 0.0010\n",
      "Epoch 49/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4ms/step - accuracy: 0.7694 - loss: 0.5321 - val_accuracy: 0.7676 - val_loss: 0.5358 - learning_rate: 0.0010\n",
      "Epoch 50/50\n",
      "\u001b[1m7875/7875\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m32s\u001b[0m 4ms/step - accuracy: 0.7717 - loss: 0.5308 - val_accuracy: 0.7721 - val_loss: 0.5332 - learning_rate: 0.0010\n",
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step - accuracy: 0.7629 - loss: 0.5484\n",
      "\n",
      "Transformer Test Accuracy: 0.7654\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
    "from tensorflow.keras import layers, models, callbacks\n",
    "import tensorflow as tf\n",
    "\n",
    "# Load dataset\n",
    "df = pd.read_csv(\"datasets/classification_data.csv\")\n",
    "\n",
    "# Label column\n",
    "label_col = 'recommended_strategy'\n",
    "y = LabelEncoder().fit_transform(df[label_col])\n",
    "\n",
    "# Feature Engineering\n",
    "df[\"income_to_networth_ratio\"] = df[\"annual_income\"] / (df[\"net_worth\"] + 1e-6)\n",
    "df[\"adjusted_debt_to_income\"] = df[\"debt_to_income_ratio\"] * df[\"annual_income\"]\n",
    "df[\"investment_savings_ratio\"] = df[\"portfolio_value\"] / (df[\"savings_rate\"] + 1e-6)\n",
    "\n",
    "# Clip to avoid negative values\n",
    "df[\"annual_income\"] = df[\"annual_income\"].clip(lower=0)\n",
    "df[\"net_worth\"] = df[\"net_worth\"].clip(lower=0)\n",
    "\n",
    "# Binned Categorical Features\n",
    "df[\"age_group\"] = pd.cut(\n",
    "    df[\"age\"], bins=[18, 35, 55, np.inf], labels=[\"Young\", \"Mid-age\", \"Senior\"], include_lowest=True\n",
    ")\n",
    "df[\"income_group\"] = pd.cut(\n",
    "    df[\"annual_income\"], bins=[0, 50000, 150000, np.inf], labels=[\"Low\", \"Medium\", \"High\"], include_lowest=True\n",
    ")\n",
    "df[\"net_worth_level\"] = pd.cut(\n",
    "    df[\"net_worth\"], bins=[0, 50000, 200000, np.inf], labels=[\"Poor\", \"Stable\", \"Wealthy\"], include_lowest=True\n",
    ")\n",
    "\n",
    "# Aggregated Scores\n",
    "df[\"total_financial_score\"] = (\n",
    "    df[\"financial_knowledge_score\"] +\n",
    "    df[\"macroeconomic_score\"] +\n",
    "    df[\"sentiment_index\"]\n",
    ")\n",
    "\n",
    "df[\"total_allocation_pct\"] = (\n",
    "    df[\"equity_allocation_pct\"] + df[\"fixed_income_allocation_pct\"]\n",
    ")\n",
    "\n",
    "# Drop ID and target label\n",
    "X = df.drop(columns=['client_id', label_col])\n",
    "\n",
    "# Handle 'month' column if exists\n",
    "if 'month' in X.columns:\n",
    "    X['month'] = pd.to_datetime(X['month'], errors='coerce')\n",
    "    X['month_num'] = X['month'].dt.month\n",
    "    X['year'] = X['month'].dt.year\n",
    "    X = X.drop(columns=['month'])\n",
    "\n",
    "# Encode all object and categorical columns\n",
    "for col in X.select_dtypes(include=['object', 'category']).columns:\n",
    "    X[col] = LabelEncoder().fit_transform(X[col].astype(str))\n",
    "\n",
    "# Fill missing values\n",
    "X = X.fillna(X.mean(numeric_only=True))\n",
    "\n",
    "# Scale features\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Reshape for Transformer input\n",
    "X_reshaped = X_scaled.reshape(X_scaled.shape[0], 1, X_scaled.shape[1])\n",
    "\n",
    "# Train-validation-test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X_reshaped, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Build Transformer model\n",
    "def build_model(input_shape, num_classes):\n",
    "    inputs = layers.Input(shape=input_shape)\n",
    "\n",
    "    # Positional encoding (for 1 timestep, positional encoding has little effect but kept for structure)\n",
    "    positions = tf.range(start=0, limit=input_shape[0], delta=1)\n",
    "    pos_embed = layers.Embedding(input_dim=input_shape[0], output_dim=input_shape[1])(positions)\n",
    "    x = inputs + pos_embed\n",
    "\n",
    "    # Transformer encoder block\n",
    "    attention = layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
    "    x = layers.Add()([x, attention])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "\n",
    "    ffn = layers.Dense(64, activation=\"relu\")(x)\n",
    "    ffn = layers.Dense(input_shape[1])(ffn)\n",
    "    x = layers.Add()([x, ffn])\n",
    "    x = layers.LayerNormalization()(x)\n",
    "\n",
    "    x = layers.Flatten()(x)\n",
    "    x = layers.Dense(64, activation=\"relu\")(x)\n",
    "    outputs = layers.Dense(num_classes, activation=\"softmax\")(x)\n",
    "\n",
    "    model = models.Model(inputs, outputs)\n",
    "    return model\n",
    "\n",
    "# Compile Model\n",
    "num_classes = len(np.unique(y))\n",
    "input_shape = X_train.shape[1:]\n",
    "\n",
    "model = build_model(input_shape, num_classes)\n",
    "model.compile(\n",
    "    loss=\"sparse_categorical_crossentropy\",\n",
    "    optimizer=\"adam\",\n",
    "    metrics=[\"accuracy\"]\n",
    ")\n",
    "\n",
    "# Callbacks\n",
    "lr_scheduler = callbacks.ReduceLROnPlateau(patience=5, factor=0.5, min_lr=1e-6, verbose=1)\n",
    "early_stop = callbacks.EarlyStopping(patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    validation_data=(X_val, y_val),\n",
    "    epochs=50,\n",
    "    batch_size=32,\n",
    "    callbacks=[lr_scheduler, early_stop],\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Evaluate\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(f\"\\nTransformer Test Accuracy: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot training & validation accuracy\n",
    "plt.figure(figsize=(12, 5))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Accuracy')\n",
    "plt.title('Model Accuracy over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Model Loss over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1688/1688\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.76      0.60      0.67     10780\n",
      "           1       0.77      0.88      0.82     27025\n",
      "           2       0.76      0.69      0.72     16195\n",
      "\n",
      "    accuracy                           0.77     54000\n",
      "   macro avg       0.76      0.72      0.74     54000\n",
      "weighted avg       0.77      0.77      0.76     54000\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x300 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "# Predict\n",
    "y_pred_probs = model.predict(X_test)\n",
    "y_pred = y_pred_probs.argmax(axis=1)\n",
    "\n",
    "# Classification report\n",
    "print(\"Classification Report:\\n\")\n",
    "print(classification_report(y_test, y_pred))\n",
    "\n",
    "# Confusion Matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "# Optional: use actual class names\n",
    "class_names = ['Conservative', 'Balanced', 'Aggressive']\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(5, 3))\n",
    "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
    "            xticklabels=class_names, yticklabels=class_names)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"Actual\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔹 Logistic Regression\n",
      "Accuracy: 0.32781944444444444\n",
      "Confusion Matrix:\n",
      " [[ 5701  3628  4826]\n",
      " [13348  9689 13158]\n",
      " [ 7834  5603  8213]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.40      0.28     14155\n",
      "           1       0.51      0.27      0.35     36195\n",
      "           2       0.31      0.38      0.34     21650\n",
      "\n",
      "    accuracy                           0.33     72000\n",
      "   macro avg       0.35      0.35      0.32     72000\n",
      "weighted avg       0.39      0.33      0.33     72000\n",
      "\n",
      "\n",
      "🔹 Random Forest Classifier\n",
      "Accuracy: 1.0\n",
      "Confusion Matrix:\n",
      " [[14155     0     0]\n",
      " [    0 36195     0]\n",
      " [    0     0 21650]]\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00     14155\n",
      "           1       1.00      1.00      1.00     36195\n",
      "           2       1.00      1.00      1.00     21650\n",
      "\n",
      "    accuracy                           1.00     72000\n",
      "   macro avg       1.00      1.00      1.00     72000\n",
      "weighted avg       1.00      1.00      1.00     72000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import required libraries\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "# Split your dataset\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X_scaled, y, test_size=0.2, stratify=y, random_state=42\n",
    ")\n",
    "\n",
    "# ----- Logistic Regression -----\n",
    "print(\"🔹 Logistic Regression\")\n",
    "logreg = LogisticRegression(max_iter=1000, class_weight='balanced', random_state=42)\n",
    "logreg.fit(X_train, y_train)\n",
    "y_pred_lr = logreg.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_lr))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_lr))\n",
    "\n",
    "# ----- Random Forest Classifier -----\n",
    "print(\"\\n🔹 Random Forest Classifier\")\n",
    "rf = RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42)\n",
    "rf.fit(X_train, y_train)\n",
    "y_pred_rf = rf.predict(X_test)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred_rf))\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Full pipeline saved successfully.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import joblib\n",
    "\n",
    "# Recreate label encoders used during training\n",
    "label_encoders = {}\n",
    "for col in df.drop(columns=['client_id', label_col]).select_dtypes(include=['object', 'category']).columns:\n",
    "    le = LabelEncoder()\n",
    "    le.fit(df[col].astype(str))\n",
    "    label_encoders[col] = le\n",
    "\n",
    "# Fit target encoder\n",
    "target_le = LabelEncoder()\n",
    "target_le.fit(df[label_col])\n",
    "\n",
    "# Save directory\n",
    "os.makedirs(\"saved_pipeline\", exist_ok=True)\n",
    "\n",
    "# Save scaler\n",
    "joblib.dump(scaler, \"saved_pipeline/scaler.pkl\")\n",
    "\n",
    "# Save label encoders for features\n",
    "for col, encoder in label_encoders.items():\n",
    "    joblib.dump(encoder, f\"saved_pipeline/encoder_{col}.pkl\")\n",
    "\n",
    "# Save label encoder for target\n",
    "joblib.dump(target_le, \"saved_pipeline/target_encoder.pkl\")\n",
    "\n",
    "# Save column names\n",
    "joblib.dump(X.columns.tolist(), \"saved_pipeline/feature_columns.pkl\")\n",
    "\n",
    "# Save label classes (optional)\n",
    "np.save(\"saved_pipeline/label_classes.npy\", target_le.classes_)\n",
    "\n",
    "# Save model\n",
    "model.save(\"saved_pipeline/transformer_model.keras\")\n",
    "\n",
    "print(\"Full pipeline saved successfully.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
