{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load datasets\n",
    "static_data = pd.read_csv(r\"datasets\\static_client_data.csv\")\n",
    "historical_data = pd.read_csv(r\"datasets\\time_series_data.csv\")\n",
    "target_data = pd.read_csv(r\"datasets\\target_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the 'month' column since it's not needed for averaging\n",
    "historical_avg = historical_data.drop(columns=[\"month\"]).groupby(\"client_id\").mean().reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              client_id  age gender employment_status  \\\n",
      "0  96c4c0a3-bb3f-4ac1-81ad-0850cd29911f   63  Other          Salaried   \n",
      "1  35fb4c11-fb1a-4eeb-addc-bd6ff6cb7934   43   Male          Salaried   \n",
      "2  e5aafbe0-c869-41d9-acf1-1b019363e449   56  Other          Salaried   \n",
      "3  43b978dd-4dd5-4f21-96d2-63ab16c814a3   37  Other           Retired   \n",
      "4  abe77866-df1b-4a5c-ad96-eb78dff4ffc9   42   Male     Self-Employed   \n",
      "\n",
      "   annual_income  debt_to_income_ratio  financial_knowledge_score  \\\n",
      "0       61244.14                  0.49                          5   \n",
      "1      111338.35                  0.39                          1   \n",
      "2       27581.32                  0.12                          5   \n",
      "3       64813.50                  0.44                          4   \n",
      "4      108668.65                  0.35                          2   \n",
      "\n",
      "      investment_goals risk_appetite  investment_horizon_years  ...  \\\n",
      "0           Retirement        Medium                         9  ...   \n",
      "1        Home Purchase           Low                        19  ...   \n",
      "2  Wealth Accumulation        Medium                        13  ...   \n",
      "3           Retirement        Medium                         3  ...   \n",
      "4            Education           Low                        19  ...   \n",
      "\n",
      "   savings_rate   net_worth  portfolio_value  equity_allocation_pct  \\\n",
      "0          0.09   150946.53    108773.212500              45.710000   \n",
      "1          0.29  1072347.37    114610.763889              49.785833   \n",
      "2          0.07   177370.90    121136.460556              53.648056   \n",
      "3          0.22   523811.23     89233.554167              53.366667   \n",
      "4          0.21   938672.67     48541.822222              51.005556   \n",
      "\n",
      "   fixed_income_allocation_pct  monthly_contribution  market_volatility_index  \\\n",
      "0                    54.290000           1229.336389                20.041667   \n",
      "1                    50.214167           1163.595556                21.256111   \n",
      "2                    46.351944           1280.783889                19.098056   \n",
      "3                    46.633333           1213.474722                19.959167   \n",
      "4                    48.994444           1178.994722                20.458056   \n",
      "\n",
      "   macroeconomic_score  sentiment_index  recommended_strategy  \n",
      "0             5.444722         5.710000          Conservative  \n",
      "1             5.697500         5.478056          Conservative  \n",
      "2             5.411944         5.429444          Conservative  \n",
      "3             5.348333         5.241389              Balanced  \n",
      "4             6.246389         5.420278              Balanced  \n",
      "\n",
      "[5 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge static data and averaged historical data\n",
    "merged_data = static_data.merge(historical_avg, on=\"client_id\", how=\"left\")\n",
    "\n",
    "# Merge with target data (only taking 'recommended_strategy')\n",
    "merged_data = merged_data.merge(target_data[[\"client_id\", \"recommended_strategy\"]], on=\"client_id\", how=\"left\")\n",
    "\n",
    "# Check the final dataset\n",
    "print(merged_data.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "client_id                      0\n",
       "age                            0\n",
       "gender                         0\n",
       "employment_status              0\n",
       "annual_income                  0\n",
       "debt_to_income_ratio           0\n",
       "financial_knowledge_score      0\n",
       "investment_goals               0\n",
       "risk_appetite                  0\n",
       "investment_horizon_years       0\n",
       "dependents                     0\n",
       "preferred_asset_classes        0\n",
       "savings_rate                   0\n",
       "net_worth                      0\n",
       "portfolio_value                0\n",
       "equity_allocation_pct          0\n",
       "fixed_income_allocation_pct    0\n",
       "monthly_contribution           0\n",
       "market_volatility_index        0\n",
       "macroeconomic_score            0\n",
       "sentiment_index                0\n",
       "recommended_strategy           0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "np.int64(0)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data[\"income_to_networth_ratio\"] = merged_data[\"annual_income\"] / (merged_data[\"net_worth\"] + 1e-6)\n",
    "merged_data[\"adjusted_debt_to_income\"] = merged_data[\"debt_to_income_ratio\"] * merged_data[\"annual_income\"]\n",
    "merged_data[\"investment_savings_ratio\"] = merged_data[\"portfolio_value\"] / (merged_data[\"savings_rate\"] + 1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data[\"annual_income\"] = merged_data[\"annual_income\"].clip(lower=0)\n",
    "merged_data[\"net_worth\"] = merged_data[\"net_worth\"].clip(lower=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "merged_data[\"age_group\"] = pd.cut(\n",
    "    merged_data[\"age\"], bins=[18, 35, 55, np.inf], labels=[\"Young\", \"Mid-age\", \"Senior\"], include_lowest=True\n",
    ")\n",
    "\n",
    "merged_data[\"income_group\"] = pd.cut(\n",
    "    merged_data[\"annual_income\"], bins=[0, 50000, 150000, np.inf], labels=[\"Low\", \"Medium\", \"High\"], include_lowest=True\n",
    ")\n",
    "\n",
    "merged_data[\"net_worth_level\"] = pd.cut(\n",
    "    merged_data[\"net_worth\"], bins=[0, 50000, 200000, np.inf], labels=[\"Poor\", \"Stable\", \"Wealthy\"], include_lowest=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_data[\"total_financial_score\"] = (\n",
    "    merged_data[\"financial_knowledge_score\"] + \n",
    "    merged_data[\"macroeconomic_score\"] + \n",
    "    merged_data[\"sentiment_index\"]\n",
    ")\n",
    "merged_data[\"total_allocation_pct\"] = merged_data[\"equity_allocation_pct\"] + merged_data[\"fixed_income_allocation_pct\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['client_id', 'age', 'gender', 'employment_status', 'annual_income',\n",
       "       'debt_to_income_ratio', 'financial_knowledge_score', 'investment_goals',\n",
       "       'risk_appetite', 'investment_horizon_years', 'dependents',\n",
       "       'preferred_asset_classes', 'savings_rate', 'net_worth',\n",
       "       'portfolio_value', 'equity_allocation_pct',\n",
       "       'fixed_income_allocation_pct', 'monthly_contribution',\n",
       "       'market_volatility_index', 'macroeconomic_score', 'sentiment_index',\n",
       "       'recommended_strategy', 'income_to_networth_ratio',\n",
       "       'adjusted_debt_to_income', 'investment_savings_ratio', 'age_group',\n",
       "       'income_group', 'net_worth_level', 'total_financial_score',\n",
       "       'total_allocation_pct'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:112: UserWarning: Features [17] are constant.\n",
      "  warnings.warn(\"Features %s are constant.\" % constant_features_idx, UserWarning)\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: invalid value encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Chi-Square Feature Importance:\n",
      "               Feature  Chi2 Score   P-value\n",
      "1   employment_status    4.053416  0.131769\n",
      "4           age_group    1.337551  0.512336\n",
      "2    investment_goals    0.837528  0.657859\n",
      "7               Bonds    0.226241  0.893043\n",
      "9        Mutual Funds    0.168171  0.919353\n",
      "3       risk_appetite    0.149767  0.927852\n",
      "8                ETFs    0.148987  0.928213\n",
      "0              gender    0.134586  0.934921\n",
      "11             Stocks    0.107243  0.947791\n",
      "10        Real Estate    0.085335  0.958230\n",
      "6     net_worth_level    0.062290  0.969335\n",
      "5        income_group    0.002733  0.998634\n",
      "\n",
      "ðŸ”¹ ANOVA (F-Test) Feature Importance:\n",
      "                         Feature   F-Score   P-value\n",
      "5                  savings_rate  1.465720  0.230961\n",
      "9               portfolio_value  1.245824  0.287748\n",
      "6                     net_worth  1.223366  0.294282\n",
      "0                           age  0.849076  0.427841\n",
      "14          macroeconomic_score  0.805871  0.446728\n",
      "3     financial_knowledge_score  0.549639  0.577176\n",
      "16        total_financial_score  0.485198  0.615590\n",
      "15              sentiment_index  0.369511  0.691082\n",
      "1                 annual_income  0.326068  0.721764\n",
      "13      market_volatility_index  0.325498  0.722175\n",
      "2          debt_to_income_ratio  0.321209  0.725279\n",
      "11  fixed_income_allocation_pct  0.296051  0.743756\n",
      "10        equity_allocation_pct  0.296051  0.743756\n",
      "12         monthly_contribution  0.209270  0.811180\n",
      "7      income_to_networth_ratio  0.133154  0.875332\n",
      "8       adjusted_debt_to_income  0.071556  0.930945\n",
      "4      investment_horizon_years  0.041452  0.959396\n",
      "17         total_allocation_pct       NaN       NaN\n",
      "\n",
      "ðŸ”¹ Mutual Information Feature Importance:\n",
      "                         Feature  MI Score\n",
      "13                annual_income  0.010837\n",
      "4                     age_group  0.010811\n",
      "23  fixed_income_allocation_pct  0.009925\n",
      "22        equity_allocation_pct  0.009664\n",
      "5                  income_group  0.007988\n",
      "25      market_volatility_index  0.007899\n",
      "24         monthly_contribution  0.007261\n",
      "11                       Stocks  0.005695\n",
      "6               net_worth_level  0.005207\n",
      "17                 savings_rate  0.005178\n",
      "26          macroeconomic_score  0.004282\n",
      "21              portfolio_value  0.003428\n",
      "10                  Real Estate  0.002832\n",
      "7                         Bonds  0.002519\n",
      "29         total_allocation_pct  0.002270\n",
      "28        total_financial_score  0.001785\n",
      "0                        gender  0.001556\n",
      "12                          age  0.001305\n",
      "1             employment_status  0.000000\n",
      "9                  Mutual Funds  0.000000\n",
      "3                 risk_appetite  0.000000\n",
      "2              investment_goals  0.000000\n",
      "8                          ETFs  0.000000\n",
      "19     income_to_networth_ratio  0.000000\n",
      "20      adjusted_debt_to_income  0.000000\n",
      "16     investment_horizon_years  0.000000\n",
      "14         debt_to_income_ratio  0.000000\n",
      "15    financial_knowledge_score  0.000000\n",
      "18                    net_worth  0.000000\n",
      "27              sentiment_index  0.000000\n",
      "\n",
      "ðŸ”¹ Random Forest Feature Importance:\n",
      "                         Feature  Importance\n",
      "26          macroeconomic_score    0.059256\n",
      "21              portfolio_value    0.057983\n",
      "24         monthly_contribution    0.057824\n",
      "25      market_volatility_index    0.057634\n",
      "27              sentiment_index    0.057140\n",
      "19     income_to_networth_ratio    0.055691\n",
      "13                annual_income    0.054427\n",
      "28        total_financial_score    0.054368\n",
      "18                    net_worth    0.053459\n",
      "20      adjusted_debt_to_income    0.052904\n",
      "22        equity_allocation_pct    0.051096\n",
      "23  fixed_income_allocation_pct    0.050927\n",
      "12                          age    0.045973\n",
      "14         debt_to_income_ratio    0.045890\n",
      "16     investment_horizon_years    0.044228\n",
      "17                 savings_rate    0.043562\n",
      "15    financial_knowledge_score    0.025925\n",
      "2              investment_goals    0.020099\n",
      "1             employment_status    0.019043\n",
      "0                        gender    0.015426\n",
      "3                 risk_appetite    0.014795\n",
      "4                     age_group    0.010810\n",
      "11                       Stocks    0.009051\n",
      "7                         Bonds    0.009014\n",
      "8                          ETFs    0.009006\n",
      "10                  Real Estate    0.008952\n",
      "9                  Mutual Funds    0.008503\n",
      "5                  income_group    0.003580\n",
      "6               net_worth_level    0.003433\n",
      "29         total_allocation_pct    0.000000\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import LabelEncoder, MultiLabelBinarizer\n",
    "from sklearn.feature_selection import chi2, SelectKBest, mutual_info_classif, f_classif\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# Handle list-type column (preferred_asset_classes)\n",
    "merged_data[\"preferred_asset_classes\"] = merged_data[\"preferred_asset_classes\"].apply(\n",
    "    lambda x: eval(x) if isinstance(x, str) else x\n",
    ")\n",
    "mlb = MultiLabelBinarizer()\n",
    "one_hot_asset_classes = pd.DataFrame(mlb.fit_transform(merged_data[\"preferred_asset_classes\"]), columns=mlb.classes_)\n",
    "merged_data = pd.concat([merged_data.drop(columns=[\"preferred_asset_classes\"]), one_hot_asset_classes], axis=1)\n",
    "\n",
    "# Identify categorical and numerical features\n",
    "categorical_cols = [\n",
    "    \"gender\", \"employment_status\", \"investment_goals\", \"risk_appetite\",\n",
    "    \"age_group\", \"income_group\", \"net_worth_level\"\n",
    "] + list(mlb.classes_)\n",
    "\n",
    "numerical_cols = [\n",
    "    \"age\", \"annual_income\", \"debt_to_income_ratio\", \"financial_knowledge_score\",\n",
    "    \"investment_horizon_years\", \"savings_rate\", \"net_worth\",\n",
    "    \"income_to_networth_ratio\", \"adjusted_debt_to_income\", 'portfolio_value', 'equity_allocation_pct', 'fixed_income_allocation_pct', \n",
    "    'monthly_contribution', 'market_volatility_index', 'macroeconomic_score', 'sentiment_index', 'total_financial_score',\n",
    "    'total_allocation_pct'\n",
    "]\n",
    "\n",
    "# Label encode categorical features (including target variable)\n",
    "encoder = LabelEncoder()\n",
    "for col in categorical_cols + [\"recommended_strategy\"]:\n",
    "    merged_data[col] = encoder.fit_transform(merged_data[col])\n",
    "\n",
    "# Define feature matrix and target variable\n",
    "X = merged_data[categorical_cols + numerical_cols]\n",
    "y = merged_data[\"recommended_strategy\"]\n",
    "\n",
    "# ---- Feature Selection ----\n",
    "\n",
    "# 1ï¸âƒ£ Chi-Square for Categorical Features\n",
    "chi2_selector = SelectKBest(chi2, k=\"all\")\n",
    "chi2_selector.fit(merged_data[categorical_cols], y)\n",
    "chi2_results = pd.DataFrame({\n",
    "    \"Feature\": categorical_cols,\n",
    "    \"Chi2 Score\": chi2_selector.scores_,\n",
    "    \"P-value\": chi2_selector.pvalues_\n",
    "}).sort_values(by=\"Chi2 Score\", ascending=False)\n",
    "\n",
    "# 2ï¸âƒ£ ANOVA F-Test for Numerical Features\n",
    "f_values, p_values = f_classif(merged_data[numerical_cols], y)\n",
    "anova_results = pd.DataFrame({\n",
    "    \"Feature\": numerical_cols,\n",
    "    \"F-Score\": f_values,\n",
    "    \"P-value\": p_values\n",
    "}).sort_values(by=\"F-Score\", ascending=False)\n",
    "\n",
    "# 3ï¸âƒ£ Mutual Information for All Features\n",
    "mi_scores = mutual_info_classif(X, y, discrete_features=\"auto\")\n",
    "mi_results = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"MI Score\": mi_scores\n",
    "}).sort_values(by=\"MI Score\", ascending=False)\n",
    "\n",
    "# 4ï¸âƒ£ Random Forest Feature Importance\n",
    "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf.fit(X, y)\n",
    "rf_importance = pd.DataFrame({\n",
    "    \"Feature\": X.columns,\n",
    "    \"Importance\": rf.feature_importances_\n",
    "}).sort_values(by=\"Importance\", ascending=False)\n",
    "\n",
    "# Display Results\n",
    "print(\"ðŸ”¹ Chi-Square Feature Importance:\\n\", chi2_results)\n",
    "print(\"\\nðŸ”¹ ANOVA (F-Test) Feature Importance:\\n\", anova_results)\n",
    "print(\"\\nðŸ”¹ Mutual Information Feature Importance:\\n\", mi_results)\n",
    "print(\"\\nðŸ”¹ Random Forest Feature Importance:\\n\", rf_importance)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ”¹ Final Selected Features:\n",
      " ['total_financial_score', 'monthly_contribution', 'risk_appetite', 'Bonds', 'ETFs', 'savings_rate', 'equity_allocation_pct', 'employment_status', 'annual_income', 'income_to_networth_ratio', 'financial_knowledge_score', 'age_group', 'Real Estate', 'age', 'portfolio_value', 'adjusted_debt_to_income', 'market_volatility_index', 'Stocks', 'Mutual Funds', 'macroeconomic_score', 'sentiment_index', 'income_group', 'fixed_income_allocation_pct', 'net_worth_level', 'investment_goals', 'net_worth', 'gender']\n"
     ]
    }
   ],
   "source": [
    "# Choose top 10 from each method\n",
    "top_chi2 = set(chi2_results.head(10)[\"Feature\"])\n",
    "top_anova = set(anova_results.head(10)[\"Feature\"])\n",
    "top_mi = set(mi_results.head(10)[\"Feature\"])\n",
    "top_rf = set(rf_importance.head(10)[\"Feature\"])\n",
    "\n",
    "# Union of top features (or intersection if you want stricter selection)\n",
    "final_features = list(top_chi2.union(top_anova).union(top_mi).union(top_rf))\n",
    "\n",
    "print(\"ðŸ”¹ Final Selected Features:\\n\", final_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = merged_data[final_features]\n",
    "y = merged_data[\"recommended_strategy\"]  # Replace with your actual target column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=0.2, random_state=42, stratify=y\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š Logistic Regression Report:\n",
      "Accuracy: 0.503\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       393\n",
      "           1       0.50      1.00      0.67      1006\n",
      "           2       0.00      0.00      0.00       601\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.17      0.33      0.22      2000\n",
      "weighted avg       0.25      0.50      0.34      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "lr = LogisticRegression(max_iter=1000)\n",
    "lr.fit(X_train_scaled, y_train)\n",
    "lr_preds = lr.predict(X_test_scaled)\n",
    "\n",
    "print(\"ðŸ“Š Logistic Regression Report:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, lr_preds))\n",
    "print(classification_report(y_test, lr_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [09:48:04] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ðŸ“Š XGBoost Report:\n",
      "Accuracy: 0.4725\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.05      0.09       393\n",
      "           1       0.52      0.78      0.62      1006\n",
      "           2       0.36      0.22      0.28       601\n",
      "\n",
      "    accuracy                           0.47      2000\n",
      "   macro avg       0.36      0.35      0.33      2000\n",
      "weighted avg       0.41      0.47      0.41      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "\n",
    "xgb = XGBClassifier(use_label_encoder=False, eval_metric='mlogloss')\n",
    "xgb.fit(X_train, y_train)\n",
    "xgb_preds = xgb.predict(X_test)\n",
    "\n",
    "print(\"ðŸ“Š XGBoost Report:\")\n",
    "print(\"Accuracy:\", accuracy_score(y_test, xgb_preds))\n",
    "print(classification_report(y_test, xgb_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.001516 seconds.\n",
      "You can set `force_col_wise=true` to remove the overhead.\n",
      "[LightGBM] [Info] Total Bins 3172\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -1.626457\n",
      "[LightGBM] [Info] Start training from score -0.687911\n",
      "[LightGBM] [Info] Start training from score -1.201476\n",
      "Accuracy: 0.479\n",
      "ðŸ“Š LightGBM Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.22      0.02      0.04       393\n",
      "           1       0.51      0.88      0.64      1006\n",
      "           2       0.32      0.11      0.17       601\n",
      "\n",
      "    accuracy                           0.48      2000\n",
      "   macro avg       0.35      0.34      0.28      2000\n",
      "weighted avg       0.39      0.48      0.38      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "lgbm_model = LGBMClassifier(random_state=42)\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_lgbm = lgbm_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_lgbm))\n",
    "print(\"ðŸ“Š LightGBM Classification Report:\")\n",
    "print(classification_report(y_test, y_pred_lgbm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.4735\n",
      "ðŸ“Š Logistic Regression (Poly Features) Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.28      0.04      0.07       393\n",
      "           1       0.50      0.86      0.64      1006\n",
      "           2       0.29      0.10      0.15       601\n",
      "\n",
      "    accuracy                           0.47      2000\n",
      "   macro avg       0.36      0.34      0.28      2000\n",
      "weighted avg       0.40      0.47      0.38      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "logistic_model = Pipeline([\n",
    "    ('scale', StandardScaler()),  # Standardizing is important before polynomial\n",
    "    ('poly', PolynomialFeatures(degree=2, include_bias=False)),\n",
    "    ('clf', LogisticRegression(max_iter=1000))\n",
    "])\n",
    "\n",
    "logistic_model.fit(X_train, y_train)\n",
    "\n",
    "y_pred_log = logistic_model.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_log))\n",
    "print(\"ðŸ“Š Logistic Regression (Poly Features) Report:\")\n",
    "print(classification_report(y_test, y_pred_log))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.002350 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 3172\n",
      "[LightGBM] [Info] Number of data points in the train set: 8000, number of used features: 27\n",
      "[LightGBM] [Info] Start training from score -1.626457\n",
      "[LightGBM] [Info] Start training from score -0.687911\n",
      "[LightGBM] [Info] Start training from score -1.201476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [09:59:30] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.489\n",
      "ðŸ“Š Voting Classifier Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.21      0.01      0.02       393\n",
      "           1       0.51      0.90      0.65      1006\n",
      "           2       0.34      0.11      0.17       601\n",
      "\n",
      "    accuracy                           0.49      2000\n",
      "   macro avg       0.35      0.34      0.28      2000\n",
      "weighted avg       0.40      0.49      0.38      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "rf_clf = RandomForestClassifier(random_state=42)\n",
    "lgbm_clf = LGBMClassifier(random_state=42)\n",
    "xgb_clf = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')\n",
    "\n",
    "voting_clf = VotingClassifier(estimators=[\n",
    "    ('rf', rf_clf), ('lgbm', lgbm_clf), ('xgb', xgb_clf)\n",
    "], voting='soft')\n",
    "\n",
    "voting_clf.fit(X_train, y_train)\n",
    "\n",
    "y_pred_vote = voting_clf.predict(X_test)\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred_vote))\n",
    "print(\"ðŸ“Š Voting Classifier Report:\")\n",
    "print(classification_report(y_test, y_pred_vote))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "\n",
    "df_processed = merged_data.copy()\n",
    "\n",
    "# Categorical feature lists\n",
    "label_encode_cols = [\"age_group\", \"income_group\", \"net_worth_level\", \"risk_appetite\", \"recommended_strategy\"]  # Ordinal categorical\n",
    "one_hot_encode_cols = [\"investment_goals\", \"employment_status\", \"gender\"]  # Nominal categorical\n",
    "multi_label_cols = [\"preferred_asset_classes\"]  # Multi-label categorical\n",
    "\n",
    "# Step 2: Label Encoding for Ordinal Categorical Features\n",
    "encoders = {}\n",
    "for col in label_encode_cols:\n",
    "    encoder = LabelEncoder()\n",
    "    df_processed[col + \"_encoded\"] = encoder.fit_transform(df_processed[col])\n",
    "    df_processed.drop(columns=[col], inplace=True)  # Remove original column\n",
    "    encoders[col] = encoder  # Store encoder for later use\n",
    "\n",
    "# Step 3: One-Hot Encoding for Nominal Categorical Features\n",
    "df_processed = pd.get_dummies(df_processed, columns=one_hot_encode_cols)\n",
    "\n",
    "# Step 4: MultiLabel Binarization for Multi-Label Features\n",
    "for col in multi_label_cols:\n",
    "    df_processed[col] = df_processed[col].apply(eval)  # Convert string lists to real lists\n",
    "    mlb = MultiLabelBinarizer()\n",
    "    mlb_encoded = pd.DataFrame(mlb.fit_transform(df_processed[col]), columns=[col + \"_\" + c for c in mlb.classes_])\n",
    "    \n",
    "    df_processed = df_processed.join(mlb_encoded).drop(columns=[col])  # Drop original multi-label column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['client_id', 'age', 'annual_income', 'debt_to_income_ratio',\n",
      "       'financial_knowledge_score', 'investment_horizon_years', 'dependents',\n",
      "       'savings_rate', 'net_worth', 'portfolio_value', 'equity_allocation_pct',\n",
      "       'fixed_income_allocation_pct', 'monthly_contribution',\n",
      "       'market_volatility_index', 'macroeconomic_score', 'sentiment_index',\n",
      "       'income_to_networth_ratio', 'adjusted_debt_to_income',\n",
      "       'investment_savings_ratio', 'total_financial_score',\n",
      "       'total_allocation_pct', 'age_group_encoded', 'income_group_encoded',\n",
      "       'net_worth_level_encoded', 'risk_appetite_encoded',\n",
      "       'recommended_strategy_encoded', 'investment_goals_Education',\n",
      "       'investment_goals_Home Purchase', 'investment_goals_Retirement',\n",
      "       'investment_goals_Wealth Accumulation', 'employment_status_Retired',\n",
      "       'employment_status_Salaried', 'employment_status_Self-Employed',\n",
      "       'employment_status_Unemployed', 'gender_Female', 'gender_Male',\n",
      "       'gender_Other', 'preferred_asset_classes_Bonds',\n",
      "       'preferred_asset_classes_ETFs', 'preferred_asset_classes_Mutual Funds',\n",
      "       'preferred_asset_classes_Real Estate',\n",
      "       'preferred_asset_classes_Stocks'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "print(df_processed.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import RobustScaler\n",
    "\n",
    "scaler = RobustScaler()\n",
    "\n",
    "y = df_processed[\"recommended_strategy_encoded\"]  # Target variable\n",
    "X = df_processed.drop(columns=[\"client_id\", \"recommended_strategy\", \"recommended_strategy_encoded\"], errors=\"ignore\")\n",
    "\n",
    "# Step 6: Standard Scaling\n",
    "scaler = RobustScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# Convert back to DataFrame\n",
    "X_scaled_df = pd.DataFrame(X_scaled, columns=X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dropped 2 highly correlated features.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Compute correlation matrix\n",
    "corr_matrix = X_scaled_df.corr().abs()\n",
    "\n",
    "# Find highly correlated features (threshold = 0.85)\n",
    "upper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "correlated_features = [column for column in upper.columns if any(upper[column] > 0.85)]\n",
    "\n",
    "# Drop highly correlated features\n",
    "X_scaled_df.drop(columns=correlated_features, inplace=True)\n",
    "\n",
    "print(f\"Dropped {len(correlated_features)} highly correlated features.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 20 most important features.\n",
      "Index(['gender_Male', 'annual_income', 'preferred_asset_classes_ETFs',\n",
      "       'equity_allocation_pct', 'net_worth_level_encoded',\n",
      "       'investment_goals_Wealth Accumulation', 'monthly_contribution',\n",
      "       'market_volatility_index', 'investment_goals_Retirement', 'dependents',\n",
      "       'portfolio_value', 'investment_horizon_years',\n",
      "       'preferred_asset_classes_Real Estate', 'gender_Other',\n",
      "       'employment_status_Self-Employed', 'investment_goals_Education',\n",
      "       'macroeconomic_score', 'total_allocation_pct',\n",
      "       'preferred_asset_classes_Bonds', 'employment_status_Salaried'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import mutual_info_classif\n",
    "\n",
    "# Compute Mutual Information scores\n",
    "mi_scores = mutual_info_classif(X_scaled_df, y)\n",
    "mi_scores = pd.Series(mi_scores, index=X_scaled_df.columns).sort_values(ascending=False)\n",
    "\n",
    "# Select top 20 most important features\n",
    "top_features = mi_scores[:20].index\n",
    "\n",
    "# Reduce dataset to selected features\n",
    "X_selected = X_scaled_df[top_features]\n",
    "\n",
    "print(f\"Selected {len(top_features)} most important features.\")\n",
    "print(X_selected.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explained variance by top 10 components: 0.76\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Keep top 10 principal components\n",
    "pca = PCA(n_components=10)\n",
    "X_pca = pca.fit_transform(X_selected)\n",
    "\n",
    "print(f\"Explained variance by top 10 components: {sum(pca.explained_variance_ratio_):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_importance = np.abs(pca.components_).sum(axis=0)\n",
    "top_features_indices = np.argsort(feature_importance)[::-1][:10]  # Get top 10 indices\n",
    "top_features = X_selected.columns[top_features_indices]  # Get feature names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 Features selected by PCA from MI-selected features:\n",
      "['equity_allocation_pct', 'market_volatility_index', 'macroeconomic_score', 'monthly_contribution', 'investment_horizon_years', 'preferred_asset_classes_Real Estate', 'preferred_asset_classes_Bonds', 'annual_income', 'portfolio_value', 'preferred_asset_classes_ETFs']\n"
     ]
    }
   ],
   "source": [
    "# âœ… Create a new DataFrame with the top 10 selected features\n",
    "X_final = X_selected[top_features]\n",
    "\n",
    "# ðŸ“Œ Display the final 10 selected features\n",
    "print(\"Top 10 Features selected by PCA from MI-selected features:\")\n",
    "print(top_features.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Accuracy: 0.4855\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.24      0.02      0.03       393\n",
      "           1       0.51      0.90      0.65      1006\n",
      "           2       0.32      0.10      0.15       601\n",
      "\n",
      "    accuracy                           0.49      2000\n",
      "   macro avg       0.36      0.34      0.28      2000\n",
      "weighted avg       0.40      0.49      0.38      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "# âœ… Split Data into Train & Test (80-20 Split)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_final, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# âœ… Train a Model (Random Forest as an example)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# âœ… Evaluate Performance\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Final Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5035\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       393\n",
      "           1       0.50      1.00      0.67      1006\n",
      "           2       0.29      0.00      0.01       601\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.26      0.33      0.23      2000\n",
      "weighted avg       0.34      0.50      0.34      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final Model Accuracy: 0.4870\n",
      "Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.12      0.01      0.01       393\n",
      "           1       0.50      0.91      0.65      1006\n",
      "           2       0.35      0.09      0.14       601\n",
      "\n",
      "    accuracy                           0.49      2000\n",
      "   macro avg       0.32      0.34      0.27      2000\n",
      "weighted avg       0.38      0.49      0.37      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# âœ… Apply PCA directly on the scaled data\n",
    "pca = PCA(n_components=10)  # Keep top 10 principal components\n",
    "X_pca = pca.fit_transform(X_scaled)\n",
    "\n",
    "# âœ… Create a DataFrame for PCA-transformed data\n",
    "X_pca_df = pd.DataFrame(X_pca, columns=[f'PC{i+1}' for i in range(10)])\n",
    "\n",
    "# âœ… Split Data into Train & Test\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_pca_df, y, test_size=0.2, random_state=42, stratify=y)\n",
    "\n",
    "# âœ… Train a Model (Random Forest as an example)\n",
    "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "clf.fit(X_train, y_train)\n",
    "\n",
    "# âœ… Evaluate Performance\n",
    "y_pred = clf.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Final Model Accuracy: {accuracy:.4f}\")\n",
    "print(\"Classification Report:\")\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5025\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       393\n",
      "           1       0.50      0.99      0.67      1006\n",
      "           2       0.37      0.01      0.02       601\n",
      "\n",
      "    accuracy                           0.50      2000\n",
      "   macro avg       0.29      0.33      0.23      2000\n",
      "weighted avg       0.36      0.50      0.34      2000\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "c:\\Users\\DELL\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    }
   ],
   "source": [
    "rf_model = RandomForestClassifier(n_estimators=200, max_depth=10, random_state=42)\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predictions\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# Evaluation Metrics\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(\"\\nClassification Report:\\n\", classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
